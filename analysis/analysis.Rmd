---
title: "Analysis for Project"
output: 
  html_document: 
    fig_height: 6
    fig_width: 9
    toc: yes
    toc_depth: 4
---


```{r time-start}
timestamp()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("analysis","check_packages.R"))
source(here("analysis","useful_functions.R"))
load(here("analysis","output","acs.RData"))
```


# Grade retention summary

OK, first lets just confirm that the grade retention variable is working as expected on our sample. I start by looking at the number of kids by age and current grade:

```{r tab-grade-by-age}
acs %>% 
  tabyl(age, current_grade) %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Cross-tabulation of age and current grade of student",
      align=c("l",rep("r",13))) %>%
  kable_paper() %>%
  column_spec(2, background=c(rep("#D3D3D3",2), rep("white", 14))) %>%
  column_spec(3, background=c("white", 
                              rep("#D3D3D3",2), 
                              rep("white", 13))) %>%
  column_spec(4, background=c(rep("white", 2), 
                              rep("#D3D3D3",2), 
                              rep("white", 12))) %>%
  column_spec(5, background=c(rep("white", 3), 
                              rep("#D3D3D3",2), 
                              rep("white", 11))) %>%
  column_spec(6, background=c(rep("white", 4), 
                              rep("#D3D3D3",2), 
                              rep("white", 10))) %>%
  column_spec(7, background=c(rep("white", 5), 
                              rep("#D3D3D3",2), 
                              rep("white", 9))) %>%
  column_spec(8, background=c(rep("white", 6), 
                              rep("#D3D3D3",2), 
                              rep("white", 8))) %>%
  column_spec(9, background=c(rep("white", 7), 
                              rep("#D3D3D3",2), 
                              rep("white", 7))) %>%
  column_spec(10, background=c(rep("white", 8), 
                               rep("#D3D3D3",2), 
                               rep("white", 6))) %>%
  column_spec(11, background=c(rep("white", 9), 
                               rep("#D3D3D3",2), 
                               rep("white", 5))) %>%
  column_spec(12, background=c(rep("white", 10), 
                               rep("#D3D3D3",2), 
                               rep("white", 4))) %>%
  column_spec(13, background=c(rep("white", 11), 
                               rep("#D3D3D3",2), 
                               rep("white", 3))) %>%
  column_spec(14, background=c(rep("white", 12), 
                               rep("#D3D3D3",2), 
                               rep("white", 2)))
```

Ok, this looks more or less like what I would expect. We observe two modal ages for each grade. Some of the more extreme age values for older grades seem a little strange given that these are only supposed to be currently enrolled students. 20-year old sixth graders? I mean there are relatively few of these cases but still seems a bit odd. Its also interesting how this really starts expanding past 5th - did the Census Bureau "correct" values below 6th or something?

Now lets calculate the percentage of cases TRUE on the dependent variable across this same table, just to confirm its all working correctly.

```{r check-retention-code}
acs %>%
  group_by(age, current_grade) %>%
  summarize(below=mean(below_exp_grade)) %>%
  ggplot(aes(x=current_grade, y=age, fill=below))+
  geom_tile(color="grey20")+
  geom_text(aes(label=below))+
  theme_bw()+
  scale_fill_viridis_c()+
  scale_y_continuous(breaks=5:20, minor_breaks = NULL)+
  labs(x="current grade", y="age", fill="proportion below grade level")
```

Ok, that looks good. 

What do the grade retention probabilities look like by grade:

```{r retention-by-grade}
acs %>%
  group_by(current_grade) %>%
  summarize(below_grade=mean(below_exp_grade),
            n=n(),
            se=sqrt((below_grade*(1-below_grade))/n)) %>%
  ggplot(aes(x=current_grade, y=below_grade, group=1,
             ymin=below_grade-1.96*se, ymax=below_grade+1.96*se))+
  geom_smooth(se=FALSE)+
  geom_line(linetype=2, color="grey30")+
  geom_point()+
  geom_linerange()+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

I guess those numbers look pretty reasonable. Its hard to benchmark it off anything. Warren et. al. estimate annual retention rates by grade but that is different than what I am measuring here because this is cumulative (but can also reflect students being caught up). In general, these must be underestimates because they do not capture kids who were held back but are still within the modal age.

What about by year?

```{r retention-by-year}
acs %>%
  group_by(year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade))+
  geom_line()+
  geom_point()+
  geom_smooth(se=FALSE)+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

Overall, there has been some decline over time in the prevalence of grade retention.

Lets look at this by grade and year

```{r retention-by-year-grade}
acs %>%
  group_by(current_grade, year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade, group=current_grade, color=current_grade))+
  geom_line()+
  geom_point()+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  scale_color_manual(values=rainbow(14))+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

The evidence here suggests that the decline is driven by the higher grades where grade retention was higher overall.

# Descriptive statistics

Lets looks at sample characteristics by race.

```{r desc-stats}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(n=n(), 
            held_back=round(mean(below_exp_grade), 3)*100,
            mean_age=round(mean(age), 1),
            f_born=round(mean(foreign_born), 3)*100,
            spk_eng_well=round(mean(spk_eng=="Yes"), 3)*100,
            spk_eng_par=round(mean(spk_eng_father=="Yes" & 
                                     spk_eng_mother=="Yes"), 3)*100,
            par_fb=round(mean(foreign_born_father | 
                                       foreign_born_mother), 3)*100,
            fam_inc=round(mean(family_income), 0),
            own_home=round(mean(own_home), 3)*100,
            par_hs=round(mean(degree_father!="LHS" | 
                                degree_mother!="LHS"), 3)*100,
            par_ba=round(mean(degree_father=="BA" | 
                                degree_father=="G" | 
                                degree_mother=="BA" | 
                                degree_mother=="G"), 3)*100,
            par_mar=round(mean(parents_married), 3)*100) %>%
  arrange(desc(n))

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Descriptive statistics by race. Shading indicates biracial group. Groups ordered by sample size.",
      align = c("l",rep("r", ncol(tbl_summary)-1)),
      col.names=c("race","n","% below expected grade", "mean age",
                  "% foreign-born","% speak English well",
                  "% Both parents speak english well","% either parent foreign-born",
                  "mean family income","% own home","% either parent, HS diploma",
                  "% Either parent, BA degree","% parents married")) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```

# Model building

## Functional form of year-grade interactions

Before running the full models, I want to test out how I can parsimoniously address differences in the time trends by grade. 

```{r models-year-grade}
model_add_cat <- glm(below_exp_grade~as.factor(year)+current_grade, 
                     data=acs, family=binomial)
model_add_cont <- glm(below_exp_grade~I(year-2010)+current_grade, 
                     data=acs, family=binomial)
model_inter_cont <- glm(below_exp_grade~I(year-2010)*current_grade, 
                     data=acs, family=binomial)
model_inter_cat <- glm(below_exp_grade~as.factor(year)*current_grade, 
                     data=acs, family=binomial)

sapply(list("categorical, additive"=model_add_cat,
            "categorical, interaction"=model_inter_cat, 
            "continuous, additive"=model_add_cont, 
            "continuous, interaction"=model_inter_cont), 
       BIC) %>%
    enframe("model","BIC") %>%
  kbl()

# free some memory
rm(model_add_cat, model_add_cont, model_inter_cat, model_inter_cont)
```

The preferred model by BIC is clearly the model that fits year as a continuous measure and interacts it with current grade, so that is what I will do. 

## Running the models

Here are the model structure that I will use:

0.  Raw race differences
1.  Add fixed effects for state, current grade, year, metro, and sex
2.  Add kids and parents foreign-born status.
3.  Add mother and father highest degree
4.  Add family income (square rooted), own your own home, and whether parents are married.

All models are estimated as logit models. Warning, the code chunks below take a bit of time to run!

```{r build-models, results='asis'}
model0 <- glm(below_exp_grade~race, data=acs, family=binomial)
model1 <- update(model0, 
                 .~.+I(year-2010)*current_grade+state+metro+sex)
model2 <- update(model1, 
                 .~.+foreign_born+foreign_born_mother+foreign_born_father+
                   spk_eng+spk_eng_mother+spk_eng_father)
model3 <- update(model2, .~.+degree_mother+degree_father)
model4 <- update(model3, .~.+sqrt(family_income/10000)+own_home+parents_married)

knitreg(list(model0, model1, model2, model3, model4))
```

## Differences for monoracial groups

The model results here are not very interesting directly because everything is relative to a single reference group. However, before proceeding with a technique for understanding the outcomes for biracial respondents, its worthwhile to look more closely at the differences between monoracial groups. The table below shows these differences using average marginal effects (AME) with whites as the reference.

```{r monoracial-results, warning=FALSE, results='asis'}
results_monoracial <- map(list(model0, model1, model2, model3, model4),
                          function(x) {
                            marg(x, "race", type="effects", 
                                 vcov_mat=vcovCL(x, cluster=acs$cluster),
                                 at_var_interest=c("White","Black","Indigenous",
                                                   "Asian","Latino"))[[1]][-1,]
                          })

knitreg(map(results_monoracial, convert_marg),
        digits=3, caption="Average marginal differences in probability of being behind grade relative to whites",
        custom.gof.rows=list("State fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Year fixed effects" =   c("No","Yes","Yes","Yes","Yes"),
                             "Grade fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Metro fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Nativity and language" = c("No","No","Yes","Yes","Yes"),
                             "Parent's education" =    c("No","No","No","Yes","Yes"),
                             "Family resources" =      c("No","No","No","No","Yes")))
```

The results indicate that controlling for everything in Model 5 reduces the racial disparities substantially. Comparing Model 5 to Model 2, the controls cut the effect in half for the Black and Indigenous groups. It has less effect and slightly increases the gap for Asians because Asians already had lower rates than Whites. The biggest change is for Latinos. In model 2, Latinos had the second highest probabilities and were 2% higher than whites. After controlling for everything, that actually reverse direction, such that Latinos have slightly lower expected probabilities than whites (.3% less). 

The gap is cut in half for Latinos by the nativity and language variables. These variables also increase the advantage of Asians as expected. they have no effect on the Black and Indigenous effects as expected.

So, I have to consider the shrinking (and in the case of Latinos, flipping direction) of these effects with controls when evaluating the placement of biracials.

## Average adjusted preditions for biracials

I want to compare each multiracial group to:

1.  Its two constituent monoracial groups (e.g. Compare Black/White to White and Black)
2.  The assumption that the biracial group will be halfway between the two constituent monoracial groups.

I can do this by calculating the *average adjusted prediction* of the dependent variable across all of the possible race groups. The average adjusted prediction (this is the stata-ese language - it is also called variously a predictive margin among other things). The adjusted predition in general is just the predicted value of the dependent variable for some set of values on the covariates. In this case, I want to predict on the level of the response to get predicted probabilities of being held back. The average adjusted prediction essentially gets the adjusted prediction for every observation in the data based on their covariates and then takes the average. Essentially, this is equivalent to treating every respondent as if they belonged to group A when calculating the average adjusted prediction for group A. The average adjusted prediction is directly related to the *average marginal effect* (AME) in that the AME for a group difference is simply the difference in the average adjusted prediction across groups.

Its easy to get a simple adjusted prediction at specific values using the `predict` command, but more complicated for the average adjusted prediction. In order to calculate these average adjusted predictions, I use the `marg` command in the `modmargs` library. This function has a nice `type="levels"` argument that directly gives you the average adjusted prediction. Standard errors for these average adjusted predictions are calculated by the [delta method](https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html). I also adjust all SEs for clustering of respondents within households.

To compare the results for each biracial group to the halfway assumption, I need to calculate the value midway between the two constituent groups and the standard error of that value. Calculating the midway value is just a straightforward mean calculation. To calculate the standard error, I take:

$$\frac{\sqrt{s_1^2+s_2^2}}{2}$$ where $s_1$ is the standard error for monoracial group 1 and $s_2$ is the standard error for monoracial group 2. This formula follows from the standard formulas for the variance of the sum of random variables.

In order to calculate all the values that I need, I have created a function that will put this into a nice table for later plotting.

```{r calc-cond-means, warning=FALSE}
coef_table_mod0 <- calculate_marg_means(model0)
```

Now I can use this nice table to plot out the results. I illustrate what this basic plot looks like below for the case of black/white individuals.

```{r example-plot}
g <- coef_table_mod0 %>%
  filter(mrace=="Black/White") %>%
  ggplot(aes(x=term, y=estimate, color=multiracial,
             ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod0, multiracial & mrace=="Black/White"))+
  geom_point()+
  coord_flip()+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial black/white respondents and monoracial\ncomparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")

g+annotate("text", 1, 0.035, hjust="left",
             label="Grey bands give 83.4%\nconfidence interval around\nmonoracial estimates")+
  annotate("text", 2, 0.045, hjust="left",
             label="Red band gives 83.4%\nconfidence interval around\nmidpoint estimate")+
  annotate("text", 2.5, 0.036, hjust="left",
             label="Actual biracial estimate\nshown with 83.4% confidence\ninterval")
```

This result is from the baseline model with no control variables, so this would be identical to the result you would get by just calculating raw proportions and their binomial standard errors (although the SEs are slightly different because this model accounts for clustering). The grey bands for the monoracial groups bookmark the range of results we might expect and the red band gives what would be the midpoint value between the groups, adjusting for statistical uncertainty. I can then see where the actual biracial estimate falls within this range. The results here indicate that biracial black/white students have probabilities of grade retention much closer to the lower values of white than black students. However, their probability is still a bit higher than that for whites.

Why I am using 83% (technically 83.4%) confidence intervals? This is a nice visual trick. People often incorrectly believe that overlapping 95% confidence intervals on two means indicates that the difference in the means is not statistically significant at $p<.05$. This is not always true and leads in practice to a much lower $\alpha$ for rejection. A much better approximation is given when one uses1.386 rather than 1.96 in estimating the confidence interval, which produces an 83.4% confidence interval. The intuition behind this technique is given nicely [here](https://chris-said.io/2014/12/01/independent-t-tests-and-the-83-confidence-interval-a-useful-trick-for-eyeballing-your-data/). Because I use this interval, we can know that if intervals (or bands) do not overlap, then the difference in means between the two groups is statistically significant at $p<.05$. In this case, the biracial estimate is statistically significantly different from both monoracial estimates as well as the "halfway" estimate. In short, biracial black/white students are held back at rates much closer but somewhat higher than whites, rather than blacks.

Its important to note that this technique is just an approximation because it depends on the assumption that the standard errors for the two means are the same, which is not going to be true here. However, it should give results that are quite close. Correcting for unequal SEs is far more complicated because the interval used will vary for any pairwise comparison which I am not doing here. 

The results here are the same as the raw differences, but I can also fit this graph to any of the models, using the average adjusted predictions. The plot below does this for model 4, by panelizing each multiracial group.

```{r cond-means-model4, warning=FALSE}
coef_table_mod4 <- calculate_marg_means(model4)

ggplot(coef_table_mod4, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod4, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, ncol=3, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

As the table here shows, after controlling for other stuff, most multiracial groups are quite similar to the monoracial constituent group with the lower grade retention rate. The only case where the biracial group is more like the higher monoracial group is for Latino/Asians. The results for indigenous groups are also quite noisy due to small size, but are generally consistent with the "below the halfway point."

To compare these results across models, I can try a very large figure that panelizes by model on the column and group on the row.

```{r cond-means-model-compare, fig.height=12, warning=FALSE}
#calculate remaining marginal means
coef_table_mod1 <- calculate_marg_means(model1)
coef_table_mod2 <- calculate_marg_means(model2)

coef_table <- coef_table_mod0 %>%
  mutate(model="crude")
coef_table <- coef_table_mod1 %>%
  mutate(model="fixed effects") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod2 %>%
  mutate(model="cultural resources") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod4 %>%
  mutate(model="parent resources") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("crude","fixed effects",
                                      "cultural resources",
                                      "parent resources")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))

ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```


## Summarizing the model results

Ok, let me first try to summarize these results, by group.

### Black/White results

For the first three models, the results are pretty consistent. Black/White biracials are much closer to the lower grade retention rates of whites, although they have rates that are clearly still higher than whites. Controlling for parental resources changes things considerably. First, the gap between Blacks and Whites shrinks considerably (visually it looks like its cut about in half). Second, Black/White biracials actually have lower rates than either group. They aren't that different than whites in effect size but the difference is statistically significant.

Why does the big change occur in the parental resources model? The descriptive stat table shows that the family resources of Black/White biracials are only slightly better than those of Black students and substantially worse than those of White students. So, Black/White biracials are at a disadvantage relative to whites, which is controlled for in the last model.

### Black/Latino results

In the crude model, its clear that there isn't much difference in the grade retention rates of Blacks and Latinos, with Blacks having a slightly higher rate than Latinos. The Black/Latino group has rates well below either of these groups. In fact, their grade retention rates in the crude model are closer to Whites. 

Interestingly, the fixed effects model reverses the ordering of Blacks and Latinos, but this is then reversed again in the cultural resources model. In addition the gap between Latinos and Blacks grows a little in the cultural resources model, which is expected. In all of these models, the Black/Latino group remains below either of those two groups, although the gap shrinks considerably across models. 

Things change quite a bit in the parent resources model. The gap between blacks and Latinos grows and the Black/Latino group now looks almost identical to the Latino group. So, some of their lower probability was due to better family resources, particularly relative to Latinos, as can be seen on the table of descriptive stats. Once that is controlled for, their outcomes are indistinguishable from Latino students.

### Black/Asian results

The crude and fixed effects models indicate that Black/Asian students have grade retention rates similar to the lower grade retention rates of Asian students. Controlling for cultural resources changes this somewhat with a point estimate that is higher than that of Asian students. This makes sense because Black/Asian students are much more likely than Asian students to be native born and speak English well with native-born parents who also speak English well. So this gave them and advantage which is removed in that model. The family resources model does not change the relative position of Black/Asian students, but does shrink the overall racial gap between Black and Asian students.

In the last two models, the confidence intervals overlap a bit, leading to greater uncertainty in the relatve placement of Black/Asian biracials. The point estimate suggests that their grade retention probability is between that of Asians and the half-way point, but the edge of the confidence intervals touch both those bands, so I cannot statistically distinguish their placement relative to those two possibilities. In any case, the results strongly rule out them being close to the outcomes of Black students, contra the hypodescent expectation.

### Black/Indigenous results

These results are quite noisy because of the smaller sample sizes involved. These are the two monoracial groups with the highest dropout rates, with or without controls. However, the difference between them is also quite large due to the very high grade retention probability for Indigenous students. This gap shrinks significantly in the model that adjusts for parental resources. 

Because of the noise its quite difficult to determine the relative placement of Black/Indigenous students at all, but we can rule out across all models that they have similar grade retentions rates to the higher grade retention of Indigenous students. The point estimate suggests a placement somewhere between the lower Black rate and the halfway point, but the wide CIs mean we cannot rule out either of those possibilities. 

The point estimate also gets much closer to the lower black rate once we control for family resources.

### White/Indigenous results

The results here consistently show that White/Indigenous students have grade retention rates about midway between the rates of whites and the halfway point. So they are clearly in the "lower half" between the groups and closer to White than Indigenous students. The overall gap between White and Indigenous students gets smaller with controls, but the relative placement of White/Indigenous students does not change.

###  White/Latino results

Importantly, the ordering of the monoracial groups shifts as controls are added to the model. The crude and fixed effets models show that White students are much less likely to be held back relative to Latino students. Controlling for cultural resources reduces this gap substantially and the inclusion of family resources flips its so that Latino students have slightly lower grade retention rates than Whites. So in the final model, there is not much room to find a midway point for White/Latino biracials. The final model shows outcomes that are similar to the lower rates of Latinos, although I need to check this more carefully because the CIs are not visible here relative to the dot (TODO). 

In the models prior to the inclusion of family resources, White/Latino biracials had grade retention rates similar to those of Whites, who had the lower rate. So despite the switch in ordering between Whites and Latinos, White/Latino biracials tend to look like the group with lower rates.

### White/Asian results

In all of the models prior to the inclusion of family resources, White/Asian students had grade retention rates slightly lower than the rates of Asians - the monoracial group with the lower rates. However, once controls are added for family resources, Asian/White students look just like Asian students (the lower group). This is because White/Asian students have the greatest family resources of any group in the dataset, even higher than those of White and Asian students. 

### Latino/Asian results

This is the group with the biggest outlier in terms of the effect. The initial results in the crude model suggested that Latino/Asian students had rates similar to the lower rates of Asian students. Controlling for cultural resources shifted this to rates that were exactly midway between the two monoracial groups. Controlling for family resources produced a point estimate that was *higher* than either monoracial group although not statistically distinguishable from the higher rates of Latinos. Notably, the gap between Asians and Latinos is also quite small in the final model. 

The change across models is a result of the high cultural and family resources of Latino/Asian students. However, their family resources do not seem particularly advantaged relative to Asian students, so something a bit complex is happening in the final model there. They look relatively worse compared to Latinos, but the relative difference doesn't change as much with respect to Asians. Essentially, once I control for family resources, they are "leapfrogged" by the Latino group.

### Indigenous/Latino results

Controlling for cultural resources makes a big difference here. Initially Indigenous/Latino students look the same as the lower Latino students. Controlling for cultural resources makes their outcomes indistinguishably from the midway point, althoug the point estimate is still in the lower half. Controlling for family resources has little effect.

Notably, because of sample size the error bars are substantially here.

### Indigenous/Asian results

This is a very small group ($n=521$) so the results are pretty noisy with wide CIs. However, the results are consistent across estimates. The grade retention rates of Indigenous/Asian students are similar to those of the lower Asian students. In the final model, the point estimate is almost identical to those for Asian students. 

Overall, I can put these results into a table where I specify the potential placement of each biracial group relative to their monoracial peers. There are seven possible outcomes:

* Lower than both groups
* Same as lower group
* Lower half
* Halfway between
* Upper half
* Same as higher
* Higher than both groups

For the two ends of the distribution and the lower half/upper half, I only consider these cases if it is statistically distinguishable from being in the other categories, respectively. For all other cases, I place an X in a cell if the confidence interval indicates this as a possibility. Asterisks indicate the placement of the point estimate for cases with uncertainty.

|                   | Lower than both | Same as lower | Lower half | Halfway | Upper half | Same as higher | Higher than both |
|-------------------|:---------------:|:-------------:|:----------:|:-------:|:----------:|:--------------:|:----------------:|
| Black/White       |        X        |               |            |         |            |                |                  |
| Black/Latino      |                 |       X       |            |         |            |                |                  |
| White/Asian       |                 |       X       |            |         |            |                |                  |
| White/Latino      |                 |       X       |            |         |            |                |                  |
| Indigenous/Asian  |                 |       X       |            |         |            |                |                  |
| Black Asian       |                 |       X       |     X*     |    X    |            |                |                  |
| Black/Indigenous  |                 |       X       |     X*     |    X    |            |                |                  |
| Indigenous/White  |                 |               |      X     |         |            |                |                  |
| Indigenous/Latino |                 |               |            |    X    |            |                |                  |
| Latino/Asian      |                 |               |            |         |            |        X       |                  |

The results I show here are based on model 4. They clearly show that most biracial groups are closer in outcomes to the monoracial group with the lower rates. In fact, half the groups have rates that are either indistinguishable from the lower group or lower than *both* groups. 

Being a part-black group in no way makes one more likely to suffer from hypodescent. In fact, the results for Black/White biracials where we would expect hypodescent to play the largest role are actually the farthest from hypodescent as possible. If any group seems to suffer from a pattern of hypodescent to some degree it is part-Indigenous groups and the Latino/Asian group. So something else is going on here.

In general, the results show that biracial groups are able to "slip through" the racialized structures that affect their more disadvantaged monoracial groups and this is not just a function of observable differences in class and nativity. 

## Sensitivity tests

### Models by grade

I want to separate the results by age more or less, but I cannot take age directly because then some kids cannot logically be behind grade at certain grade levels. For example, if I restrict to 11 or younger, then none of the 5th graders will be behind grade, by design. So, I will restrict by current grade level which indirectly gets at age. I am going to split it by elementary, middle school, and high school.

```{r models-by-grade, warning=FALSE, fig.height=12}
#run separate models by grade groups
model4_elem <- update(model4, data=subset(acs, current_grade<="5th"))
model4_middle <- update(model4, data=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th"))
model4_hs <- update(model4, data=subset(acs, current_grade>="9th"))


coef_table_elem <- calculate_marg_means(model4_elem, 
                                        cluster_var=subset(acs, current_grade<="5th")$cluster)
coef_table_middle <- calculate_marg_means(model4_middle,
                                          cluster_var=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th")$cluster)
coef_table_hs <- calculate_marg_means(model4_hs,
                                      cluster_var=subset(acs, current_grade>="9th")$cluster)

coef_table <- coef_table_elem %>%
  mutate(model="elementary")
coef_table <- coef_table_middle %>%
  mutate(model="middle school") %>%
  bind_rows(coef_table)
coef_table <- coef_table_hs %>%
  mutate(model="high school") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("elementary","middle school",
                                      "high school")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

The results get quite a bit noisier here because we are cutting the sample size substantially in each panel. The general pattern is that the results tend to look pretty similar across grade levels. What variations we do see could easily be the result of statistical noise as they tend to move around the most in cases with high error bands. The two notable cases where something might be going on:

* For White/Black students, grade retention is clearly in the lower-half between Whites and the midway point rather than below whites for high school students. Notably, this is also where the white/black grows the largest. So the advantage that these students have relative to everyone else only holds for elementary and middle school. Nonetheless, their outcomes are still much closer to White students than Black students.
* For White/Indigenous students, the placement varies across panels. In elementary school, these students are indistinguishable from White students. They are perfectly in the middle in middle school, and then in the lower half in high school. So it seems that their lowest outcomes happen earlier and on average you end up with a "lower half" across all grades. 

In no case do the results here suggest a biasing effect of non-biological kids. We would expect that to be greater in higher grades, but the results are generally consistent across grades. In cases where they are not consistent, you would expect the results to move toward the larger population group with age, but I do not see that.

### Models with stricter parent linking

```{r models-parent-link, warning=FALSE, fig.height=12}
#run separate models by grade groups
model4_best_link <- update(model4, data=subset(acs, momrule==11 & poprule==11))

coef_table_best_link <- calculate_marg_means(model4_best_link, 
                                        cluster_var=subset(acs, momrule==11 &
                                                             poprule==11)$cluster)

coef_table <- coef_table_best_link %>%
  mutate(model="only direct links")
coef_table <- coef_table_mod4 %>%
  mutate(model="all links") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("all links","only direct links")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

The results here are extraordinarily stable across both specifications. 

# Differences in Cultural and Family Resources

I want a parsimonious way to visualize differences in cultural and family resources. I can sort of do it by looking at the big descriptive statistics table, but it can be a little hard to summarize. Doing each possible variable separately would be extremely tedious here, so I am going to create scores across variables for these two measures and then model them as outcomes. I can then plot the results just like I do for my actual outcome measure. 

I will start by just looking at the $\alpha$ score for the correlation matrix of each case. I then create scores scaled to have a mean of zero and a standard deviation of one and fit these with a linear model using the same structure as for the models above.

## Cultural Resources

```{r cult-resource-alpha}
cult_resources <- cbind(as.numeric(!acs$foreign_born), 
                        as.numeric(!acs$foreign_born_father), 
                        as.numeric(!acs$foreign_born_mother),
                        as.numeric(factor(acs$spk_eng, 
                                          levels=c("No","Somewhat","Yes"))),
                        as.numeric(factor(acs$spk_eng_father, 
                                          levels=c("No","Somewhat","Yes"))),
                        as.numeric(factor(acs$spk_eng_mother, 
                                          levels=c("No","Somewhat","Yes"))))

alpha(cor(cult_resources))
```

That all holds together well. However, I run into a problem when I think about making a score out of this because the foreign-born status of parents actually helps to reduce the likelihood of grade retention while all of the other variables increase it. For now, I am just reverse coding it, but this leads to results that are far from intuitive. I think the simple score approach might not work well in this case.

```{r cult-resource-score}
#scale them all, add them up, and then scale again
#one catch though, I want to reverse score foreign born mother and father
#because these reduce the likelihood of grade retention, other things
#controlled
acs$cult_resources <- scale(scale(as.numeric(!acs$foreign_born))+
                              scale(as.numeric(acs$foreign_born_father))+
                              scale(as.numeric(acs$foreign_born_mother))+
                              scale(as.numeric(factor(acs$spk_eng, 
                                          levels=c("No","Somewhat","Yes"))))+
                              scale(as.numeric(factor(acs$spk_eng_father, 
                                          levels=c("No","Somewhat","Yes"))))+
                              scale(as.numeric(factor(acs$spk_eng_mother, 
                                          levels=c("No","Somewhat","Yes")))))
```

```{r cult-resource-model, warning=FALSE}
#If I use the glm framework then I should be able to feed this back into
#the marg command
model_cultr <- glm(cult_resources~race+I(year-2010)*current_grade+state+metro+sex+
                    +degree_mother+degree_father+sqrt(family_income/10000)+
                     own_home+parents_married, 
                  data=acs, family="gaussian")
coef_table_cultr <- calculate_marg_means(model_cultr)

ggplot(coef_table_cultr, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_cultr, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  labs(x=NULL,
       y="average adjusted cultural resource score (standard deviation units)",
       title="Average cultural resources for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

Because of the issue with foreign-born parents, these results are not particularly intuitive. It tends to show that part-Asian and part-Latino respondents have high cultural resources, but generally not higher than the highest of their constituent groups. Other groups have results half-way in between.

## Family Resources

```{r fam-resource-score, warning=FALSE}
fam_resources <- cbind(acs$family_income, as.numeric(acs$degree_father), 
                       as.numeric(acs$degree_mother), as.numeric(acs$own_home))

alpha(cor(fam_resources))

#scale them all, add them up, and then scale again
acs$fam_resources <- scale(scale(acs$family_income)+scale(acs$own_home)+
  scale(as.numeric(acs$degree_father)+scale(as.numeric(acs$degree_mother))))
```


```{r fam-resource-model}
#If I use the glm framework then I should be able to feed this back into
#the marg command
model_famr <- glm(fam_resources~race+I(year-2010)*current_grade+state+metro+sex+
                    foreign_born+foreign_born_mother+foreign_born_father+
                    spk_eng+spk_eng_mother+spk_eng_father, 
                  data=acs, family="gaussian")
coef_table_famr <- calculate_marg_means(model_famr)

ggplot(coef_table_famr, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_famr, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  labs(x=NULL,
       y="average adjusted family resource score (standard deviation units)",
       title="Average family resources for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

In most cases, family resources are roughly midway between those of the two monoracial groups. However, there are a couple of notable exceptions:

* The average family resources of Black/White students are only marginally better than those of Black students which are far below those of the average white students.
* The White/Asian group has family resources higher then either of the two constituent groups which already have the highest resources of any monoracial group. The White/Asian group has the highest family resources of any group here.
* The Indigenous/Latino and Black/Latino groups have family resources slightly lower than either of hte constituent groups, but in both cases there are hardly any differences between the monoracial groups themselves. So you would not expect controlling for these variables to change much for these groups.

```{r time-end}
timestamp()
```