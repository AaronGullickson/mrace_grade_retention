---
title: "Analysis for Project"
output: 
  html_document: 
    fig_height: 6
    fig_width: 9
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("analysis","check_packages.R"))
source(here("analysis","useful_functions.R"))
load(here("analysis","output","acs.RData"))
```

# Grade retention summary

OK, first lets just confirm that the grade retention variable is working as expected on our sample. I start by looking at the number of kids by age and current grade:

```{r tab-grade-by-age}
tbl <- table(acs$age, acs$current_grade) 

acs %>% 
  tabyl(age, current_grade) %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Cross-tabulation of age and current grade of student",
      align=c("l",rep("r",13))) %>%
  kable_paper() %>%
  column_spec(2, background=c(rep("#D3D3D3",2), rep("white", 14))) %>%
  column_spec(3, background=c("white", 
                              rep("#D3D3D3",2), 
                              rep("white", 13))) %>%
  column_spec(4, background=c(rep("white", 2), 
                              rep("#D3D3D3",2), 
                              rep("white", 12))) %>%
  column_spec(5, background=c(rep("white", 3), 
                              rep("#D3D3D3",2), 
                              rep("white", 11))) %>%
  column_spec(6, background=c(rep("white", 4), 
                              rep("#D3D3D3",2), 
                              rep("white", 10))) %>%
  column_spec(7, background=c(rep("white", 5), 
                              rep("#D3D3D3",2), 
                              rep("white", 9))) %>%
  column_spec(8, background=c(rep("white", 6), 
                              rep("#D3D3D3",2), 
                              rep("white", 8))) %>%
  column_spec(9, background=c(rep("white", 7), 
                              rep("#D3D3D3",2), 
                              rep("white", 7))) %>%
  column_spec(10, background=c(rep("white", 8), 
                               rep("#D3D3D3",2), 
                               rep("white", 6))) %>%
  column_spec(11, background=c(rep("white", 9), 
                               rep("#D3D3D3",2), 
                               rep("white", 5))) %>%
  column_spec(12, background=c(rep("white", 10), 
                               rep("#D3D3D3",2), 
                               rep("white", 4))) %>%
  column_spec(13, background=c(rep("white", 11), 
                               rep("#D3D3D3",2), 
                               rep("white", 3))) %>%
  column_spec(14, background=c(rep("white", 12), 
                               rep("#D3D3D3",2), 
                               rep("white", 2)))
```

Ok, this looks more or less like what I would expect. We observe two modal ages for each grade. Some of the more extreme age values for older grades seem a little strange given that these are only supposed to be currently enrolled students. 20-year old sixth graders? I mean there are relatively few of these cases but still seems a bit odd. Its also interesting how this really starts expanding past 5th - did the Census Bureau "correct" values below 6th or something?

Now lets calculate the percentage of cases TRUE on the dependent variable across this same table, just to confirm its all working correctly.

```{r check-retention-code}
tapply(acs$below_exp_grade,acs[,c("age","current_grade")], mean)
```

Ok, that looks good. NAs indicate cells with no cases. The 1 values start with 7 year old Kindergarteners and then move down in a perfect diagonal from there. So this looks good.

What do the grade retention probabilities look like by grade:

```{r retention-by-grade}
acs %>%
  group_by(current_grade) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=current_grade, y=below_grade))+
  geom_col()+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

I guess those numbers look pretty reasonable. Its hard to benchmark it off anything. Warren et. al. estimate annual retention rates by grade but that is different than what I am measuring here because this is cumulative (but can also reflect students being caught up). In general, these must be underestimates because they do not capture kids who were held back but are still within the modal age.

What about by year?

```{r retention-by-year}
acs %>%
  group_by(year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade))+
  geom_line()+
  geom_point()+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

Overall, there has been some decline over time in the prevalence of grade retention.

Lets look at this by grade and year

```{r retention-by-year-grade}
acs %>%
  group_by(current_grade, year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade, group=current_grade, color=current_grade))+
  geom_line()+
  geom_point()+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  scale_color_viridis_d()+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

The evidence here suggests that the decline is driven by the higher grades where grade retention was higher overall.

# Descriptive statistics

Lets looks at sample characteristics by race.

```{r desc-stats}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(n=n(), 
            held_back=round(mean(below_exp_grade), 3)*100,
            mean_age=round(mean(age), 1),
            f_born=round(mean(foreign_born), 3)*100,
            spk_eng_well=round(mean(spk_eng=="Yes"), 3)*100,
            spk_eng_par=round(mean(spk_eng_father=="Yes" & 
                                     spk_eng_mother=="Yes"), 3)*100,
            par_fb=round(mean(foreign_born_father | 
                                       foreign_born_mother), 3)*100,
            fam_inc=round(mean(family_income), 0),
            own_home=round(mean(own_home), 3)*100,
            par_hs=round(mean(degree_father!="LHS" | 
                                degree_mother!="LHS"), 3)*100,
            par_ba=round(mean(degree_father=="BA" | 
                                degree_father=="G" | 
                                degree_mother=="BA" | 
                                degree_mother=="G"), 3)*100,
            par_mar=round(mean(parents_married), 3)*100) %>%
  arrange(desc(n))

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Descriptive statistics by race. Shading indicates biracial group. Groups ordered by sample size.", align = c("l",rep("r", ncol(tbl_summary)-1))) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```

# Model building time

Here are the model structure that I will use:

0.  Raw race differences
1.  Add fixed effects for state, current grade, year, and metro
2.  Add kids and parents foreign-born status.
3.  Add mother and father highest degree
4.  Add family income (square rooted), own your own home, and whether parents are married.

All models are estimated as logit models. Warning, the code chunks below take a bit of time to run!

```{r build-models, results='asis'}
model0 <- glm(below_exp_grade~race, data=acs, family=binomial)
model1 <- update(model0, .~.+as.factor(year)+current_grade+as.factor(state)+metro)
model2 <- update(model1, 
                 .~.+foreign_born+foreign_born_mother+foreign_born_father+
                   spk_eng+spk_eng_mother+spk_eng_father)
model3 <- update(model2, .~.+degree_mother+degree_father)
model4 <- update(model3, .~.+sqrt(family_income/10000)+own_home+parents_married)

knitreg(list(model0, model1, model2, model3, model4))
```

The model results themselves are not that useful. I want to compare each multiracial group to:

1.  Its two constituent monoracial groups (e.g. Compare Black/White to White and Black)
2.  The assumption that the biracial group will be halfway between the two constituent monoracial groups.

I can do this by calculating marginal means (or proportions to be more accurate) of the dependent variable across all of the possible race groups. In order to calculate these marginal means, I use the `marg` command in the `modmargs` library. This gives me results equivalent to average marginal effects but on the level (e.g. mean) rather than the effect (different in mean). Standard errors for these marginal means are calculated by the [delta method](https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html). I adjust all SEs for clustering of respondents within households.

To compare the results for each biracial group to the halfway assumption, I need to calculate the value midway between the two consituent groups and the standard error of that value. Calculating the midway value is just a straightforward mean calculation. To calculate the standard error, I take:

$$\frac{\sqrt{s_1^2+s_2^2}}{2}$$ where $s_1$ is the standard error for monoracial group 1 and $s_2$ is the standard error for monoracial group 2. This formula follows from the standard formulas for the variance of the sum of random variables.

In order to calculate all the values that I need, I have created a function that will put this into a nice table for later plotting.

```{r calc-cond-means, warning=FALSE}
coef_table_mod0 <- calculate_marg_means(model0)
```

Now I can use this nice table to plot out the results. I illustrate what this basic plot looks like below for the case of black/white individuals.

```{r example-plot}
g <- coef_table_mod0 %>%
  filter(mrace=="Black/White") %>%
  ggplot(aes(x=term, y=estimate, color=multiracial,
             ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod0, multiracial & mrace=="Black/White"))+
  geom_point()+
  coord_flip()+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial black/white respondents and monoracial\ncomparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")

g+annotate("text", 1, 0.035, hjust="left",
             label="Grey bands give 83.4%\nconfidence interval around\nmonoracial estimates")+
  annotate("text", 2, 0.045, hjust="left",
             label="Red band gives 83.4%\nconfidence interval around\nmidpoint estimate")+
  annotate("text", 2.5, 0.036, hjust="left",
             label="Actual biracial estimate\nshown with 83.4% confidence\ninterval")
```

This result is from the baseline model with no control variables, so this would be identical to the result you would get by just calculating raw proportions and their binomial standard errors (although the SEs are slightly different because this model accounts for clustering). The grey bands for the monoracial groups bookmark the range of results we might expect and the red band gives what would be the midpoint value between the groups, adjusting for statistical uncertainty. I can then see where the actual biracial estimate falls within this range. The results here indicate that biracial black/white students have probabilities of grade retention much closer to the lower values of white than black students. However, their probability is still a bit higher than that for whites.

Why I am using 83% (technically 83.4%) confidence intervals? This is a nice visual trick. People often incorrectly believe that overlapping 95% confidence intervals on two means indicates that the difference in the means is not statistically significant at $p<.05$. This is not always true and leads in practice to a much lower $\alpha$ for rejection. For that to be true, one needs to use 1.386 rather than 1.96 in estimating the confidence interval which produces an 83.4% confidence interval. It turns out that 1.386 is equal to $1.96/\sqrt{2}$. The intuition behind this technique is given nicely [here](https://chris-said.io/2014/12/01/independent-t-tests-and-the-83-confidence-interval-a-useful-trick-for-eyeballing-your-data/). Because I use this interval, we can know that if intervals (or bands) do not overlap, then the difference in means between the two groups is statistically significant at $p<.05$. In this case, the biracial estimate is statistically significantly different from both monoracial estimates as well as the "halfway" estimate. In short, biracial black/white students are held back at rates much closer but somewhat higher than whites, rather than blacks.

The results here are the same as the raw differences, but I can also fit this graph to any of the models, so I can effectively give conditional probabilities. The plot below does this for model 4, by panelizing each multiracial group.

```{r cond-means-model4, warning=FALSE}
coef_table_mod4 <- calculate_marg_means(model4)

ggplot(coef_table_mod4, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod4, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, ncol=3, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

As the table here shows, after controlling for other stuff, most multiracial groups are quite similar to the monoracial constituent group with the lower grade retention rate. The only case where the biracial group is more like the higher monoracial group is for Latino/Asians. The results for indigenous groups are also quite noisy due to small size, but are generally consistent with the "below the halfway point."

To compare these results across models, I can try a very large figure that panelizes by model on the column and group on the row.

```{r cond-means-model-compare, fig.height=12, warning=FALSE}
#calculate remaining marginal means
coef_table_mod1 <- calculate_marg_means(model1)
coef_table_mod2 <- calculate_marg_means(model2)

coef_table <- coef_table_mod0 %>%
  mutate(model="crude")
coef_table <- coef_table_mod1 %>%
  mutate(model="fixed effects") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod2 %>%
  mutate(model="cultural resources") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod4 %>%
  mutate(model="parent resources") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("crude","fixed effects",
                                      "cultural resources",
                                      "parent resources")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))

ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

Summarize these results.

# Sensitivity tests

```{r models-by-age, eval=FALSE}
#run separate models by grade groups
model4a <- update(model4, data=subset(acs, as.numeric(current_grade)<=6))
model4b <- update(model4, data=subset(acs, as.numeric(current_grade)>6 &
                                        as.numeric(current_grade)<=9))
model4c <- update(model4, data=subset(acs, as.numeric(current_grade)>=10))

knitreg(list(model4a, model4b, model4c))
```



