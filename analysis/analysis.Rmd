---
title: "Analysis for Project"
output: 
  html_document: 
    fig_height: 6
    fig_width: 9
    toc: yes
    toc_depth: 4
---


```{r time-start}
timestamp()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("analysis","check_packages.R"))
source(here("analysis","useful_functions.R"))
load(here("analysis","output","acs.RData"))
```


# Grade retention summary

OK, first lets just confirm that the grade retention variable is working as expected on our sample. I start by looking at the number of kids by age and current grade:

```{r tab-grade-by-age}
acs %>% 
  tabyl(age, current_grade) %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Cross-tabulation of age and current grade of student",
      align=c("l",rep("r",13))) %>%
  kable_paper() %>%
  column_spec(2, background=c(rep("#D3D3D3",2), rep("white", 14))) %>%
  column_spec(3, background=c("white", 
                              rep("#D3D3D3",2), 
                              rep("white", 13))) %>%
  column_spec(4, background=c(rep("white", 2), 
                              rep("#D3D3D3",2), 
                              rep("white", 12))) %>%
  column_spec(5, background=c(rep("white", 3), 
                              rep("#D3D3D3",2), 
                              rep("white", 11))) %>%
  column_spec(6, background=c(rep("white", 4), 
                              rep("#D3D3D3",2), 
                              rep("white", 10))) %>%
  column_spec(7, background=c(rep("white", 5), 
                              rep("#D3D3D3",2), 
                              rep("white", 9))) %>%
  column_spec(8, background=c(rep("white", 6), 
                              rep("#D3D3D3",2), 
                              rep("white", 8))) %>%
  column_spec(9, background=c(rep("white", 7), 
                              rep("#D3D3D3",2), 
                              rep("white", 7))) %>%
  column_spec(10, background=c(rep("white", 8), 
                               rep("#D3D3D3",2), 
                               rep("white", 6))) %>%
  column_spec(11, background=c(rep("white", 9), 
                               rep("#D3D3D3",2), 
                               rep("white", 5))) %>%
  column_spec(12, background=c(rep("white", 10), 
                               rep("#D3D3D3",2), 
                               rep("white", 4))) %>%
  column_spec(13, background=c(rep("white", 11), 
                               rep("#D3D3D3",2), 
                               rep("white", 3))) %>%
  column_spec(14, background=c(rep("white", 12), 
                               rep("#D3D3D3",2), 
                               rep("white", 2)))
```

Ok, this looks more or less like what I would expect. We observe two modal ages for each grade. Some of the more extreme age values for older grades seem a little strange given that these are only supposed to be currently enrolled students. 20-year old sixth graders? I mean there are relatively few of these cases but still seems a bit odd. Its also interesting how this really starts expanding past 5th - did the Census Bureau "correct" values below 6th or something?

Now lets calculate the percentage of cases TRUE on the dependent variable across this same table, just to confirm its all working correctly.

```{r check-retention-code}
acs %>%
  group_by(age, current_grade) %>%
  summarize(below=mean(below_exp_grade)) %>%
  ggplot(aes(x=current_grade, y=age, fill=below))+
  geom_tile(color="grey20")+
  geom_text(aes(label=below))+
  theme_bw()+
  scale_fill_viridis_c()+
  scale_y_continuous(breaks=5:20, minor_breaks = NULL)+
  labs(x="current grade", y="age", fill="proportion below grade level")
```

Ok, that looks good. 

What do the grade retention probabilities look like by grade:

```{r retention-by-grade}
acs %>%
  group_by(current_grade) %>%
  summarize(below_grade=mean(below_exp_grade),
            n=n(),
            se=sqrt((below_grade*(1-below_grade))/n)) %>%
  ggplot(aes(x=current_grade, y=below_grade, group=1,
             ymin=below_grade-1.96*se, ymax=below_grade+1.96*se))+
  geom_smooth(se=FALSE)+
  geom_line(linetype=2, color="grey30")+
  geom_point()+
  geom_linerange()+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

I guess those numbers look pretty reasonable. Its hard to benchmark it off anything. Warren et. al. estimate annual retention rates by grade but that is different than what I am measuring here because this is cumulative (but can also reflect students being caught up). In general, these must be underestimates because they do not capture kids who were held back but are still within the modal age.

What about by year?

```{r retention-by-year}
acs %>%
  group_by(year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade))+
  geom_line()+
  geom_point()+
  geom_smooth(se=FALSE)+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

Overall, there has been some decline over time in the prevalence of grade retention.

Lets look at this by grade and year

```{r retention-by-year-grade}
acs %>%
  group_by(current_grade, year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade, group=current_grade, color=current_grade))+
  geom_line()+
  geom_point()+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  scale_color_manual(values=rainbow(14))+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

The evidence here suggests that the decline is driven by the higher grades where grade retention was higher overall.

# Descriptive statistics

Lets looks at sample characteristics by race.

```{r desc-stats}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(n=n(), 
            held_back=round(mean(below_exp_grade), 3)*100,
            mean_age=round(mean(age), 1),
            f_born=round(mean(foreign_born), 3)*100,
            spk_eng_well=round(mean(spk_eng=="Yes"), 3)*100,
            spk_eng_par=round(mean(spk_eng_father=="Yes" & 
                                     spk_eng_mother=="Yes"), 3)*100,
            par_fb=round(mean(foreign_born_father | 
                                       foreign_born_mother), 3)*100,
            fam_inc=round(mean(family_income), 0),
            own_home=round(mean(own_home), 3)*100,
            par_hs=round(mean(degree_father!="LHS" | 
                                degree_mother!="LHS"), 3)*100,
            par_ba=round(mean(degree_father=="BA" | 
                                degree_father=="G" | 
                                degree_mother=="BA" | 
                                degree_mother=="G"), 3)*100,
            par_mar=round(mean(parents_married), 3)*100) %>%
  arrange(desc(n))

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Descriptive statistics by race. Shading indicates biracial group. Groups ordered by sample size.",
      align = c("l",rep("r", ncol(tbl_summary)-1)),
      col.names=c("race","n","% below expected grade", "mean age",
                  "% foreign-born","% speak English well",
                  "% Both parents speak english well","% either parent foreign-born",
                  "mean family income","% own home","% either parent, HS diploma",
                  "% Either parent, BA degree","% parents married")) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```

# Model building time

Here are the model structure that I will use:

0.  Raw race differences
1.  Add fixed effects for state, current grade, year, metro, and sex
2.  Add kids and parents foreign-born status.
3.  Add mother and father highest degree
4.  Add family income (square rooted), own your own home, and whether parents are married.

All models are estimated as logit models. 

Before running the full models, I want to test out how I can parsimoniously address differences in the time trends by grade. 

```{r models-year-grade}
model_add_cat <- glm(below_exp_grade~as.factor(year)+current_grade, 
                     data=acs, family=binomial)
model_add_cont <- glm(below_exp_grade~I(year-2010)+current_grade, 
                     data=acs, family=binomial)
model_inter_cont <- glm(below_exp_grade~I(year-2010)*current_grade, 
                     data=acs, family=binomial)
model_inter_cat <- glm(below_exp_grade~as.factor(year)*current_grade, 
                     data=acs, family=binomial)

sapply(list("categorical, additive"=model_add_cat,
            "categorical, interaction"=model_inter_cat, 
            "continuous, additive"=model_add_cont, 
            "continuous, interaction"=model_inter_cont), 
       BIC) %>%
    enframe("model","BIC") %>%
  kbl()

# free some memory
rm(model_add_cat, model_add_cont, model_inter_cat, model_inter_cont)
```

The preferred model by BIC is clearly the model that fits year as a continuous measure and interacts it with current grade, so that is what I will do. 

Now lets run the full models. Warning, the code chunks below take a bit of time to run!

```{r build-models, results='asis'}
model0 <- glm(below_exp_grade~race, data=acs, family=binomial)
model1 <- update(model0, 
                 .~.+I(year-2010)*current_grade+state+metro+sex)
model2 <- update(model1, 
                 .~.+foreign_born+foreign_born_mother+foreign_born_father+
                   spk_eng+spk_eng_mother+spk_eng_father)
model3 <- update(model2, .~.+degree_mother+degree_father)
model4 <- update(model3, .~.+sqrt(family_income/10000)+own_home+parents_married)

knitreg(list(model0, model1, model2, model3, model4))
```

The model results themselves are not that useful. I want to compare each multiracial group to:

1.  Its two constituent monoracial groups (e.g. Compare Black/White to White and Black)
2.  The assumption that the biracial group will be halfway between the two constituent monoracial groups.

I can do this by calculating marginal means (or proportions to be more accurate) of the dependent variable across all of the possible race groups. In order to calculate these marginal means, I use the `marg` command in the `modmargs` library. This gives me results equivalent to average marginal effects but on the level (e.g. mean) rather than the effect (different in mean). Standard errors for these marginal means are calculated by the [delta method](https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html). I adjust all SEs for clustering of respondents within households.

To compare the results for each biracial group to the halfway assumption, I need to calculate the value midway between the two consituent groups and the standard error of that value. Calculating the midway value is just a straightforward mean calculation. To calculate the standard error, I take:

$$\frac{\sqrt{s_1^2+s_2^2}}{2}$$ where $s_1$ is the standard error for monoracial group 1 and $s_2$ is the standard error for monoracial group 2. This formula follows from the standard formulas for the variance of the sum of random variables.

In order to calculate all the values that I need, I have created a function that will put this into a nice table for later plotting.

```{r calc-cond-means, warning=FALSE}
coef_table_mod0 <- calculate_marg_means(model0)
```

Now I can use this nice table to plot out the results. I illustrate what this basic plot looks like below for the case of black/white individuals.

```{r example-plot}
g <- coef_table_mod0 %>%
  filter(mrace=="Black/White") %>%
  ggplot(aes(x=term, y=estimate, color=multiracial,
             ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod0, multiracial & mrace=="Black/White"))+
  geom_point()+
  coord_flip()+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial black/white respondents and monoracial\ncomparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")

g+annotate("text", 1, 0.035, hjust="left",
             label="Grey bands give 83.4%\nconfidence interval around\nmonoracial estimates")+
  annotate("text", 2, 0.045, hjust="left",
             label="Red band gives 83.4%\nconfidence interval around\nmidpoint estimate")+
  annotate("text", 2.5, 0.036, hjust="left",
             label="Actual biracial estimate\nshown with 83.4% confidence\ninterval")
```

This result is from the baseline model with no control variables, so this would be identical to the result you would get by just calculating raw proportions and their binomial standard errors (although the SEs are slightly different because this model accounts for clustering). The grey bands for the monoracial groups bookmark the range of results we might expect and the red band gives what would be the midpoint value between the groups, adjusting for statistical uncertainty. I can then see where the actual biracial estimate falls within this range. The results here indicate that biracial black/white students have probabilities of grade retention much closer to the lower values of white than black students. However, their probability is still a bit higher than that for whites.

Why I am using 83% (technically 83.4%) confidence intervals? This is a nice visual trick. People often incorrectly believe that overlapping 95% confidence intervals on two means indicates that the difference in the means is not statistically significant at $p<.05$. This is not always true and leads in practice to a much lower $\alpha$ for rejection. For that to be true, one needs to use 1.386 rather than 1.96 in estimating the confidence interval which produces an 83.4% confidence interval. It turns out that 1.386 is equal to $1.96/\sqrt{2}$. The intuition behind this technique is given nicely [here](https://chris-said.io/2014/12/01/independent-t-tests-and-the-83-confidence-interval-a-useful-trick-for-eyeballing-your-data/). Because I use this interval, we can know that if intervals (or bands) do not overlap, then the difference in means between the two groups is statistically significant at $p<.05$. In this case, the biracial estimate is statistically significantly different from both monoracial estimates as well as the "halfway" estimate. In short, biracial black/white students are held back at rates much closer but somewhat higher than whites, rather than blacks.

The results here are the same as the raw differences, but I can also fit this graph to any of the models, so I can effectively give conditional probabilities. The plot below does this for model 4, by panelizing each multiracial group.

```{r cond-means-model4, warning=FALSE}
coef_table_mod4 <- calculate_marg_means(model4)

ggplot(coef_table_mod4, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod4, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, ncol=3, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

As the table here shows, after controlling for other stuff, most multiracial groups are quite similar to the monoracial constituent group with the lower grade retention rate. The only case where the biracial group is more like the higher monoracial group is for Latino/Asians. The results for indigenous groups are also quite noisy due to small size, but are generally consistent with the "below the halfway point."

To compare these results across models, I can try a very large figure that panelizes by model on the column and group on the row.

```{r cond-means-model-compare, fig.height=12, warning=FALSE}
#calculate remaining marginal means
coef_table_mod1 <- calculate_marg_means(model1)
coef_table_mod2 <- calculate_marg_means(model2)

coef_table <- coef_table_mod0 %>%
  mutate(model="crude")
coef_table <- coef_table_mod1 %>%
  mutate(model="fixed effects") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod2 %>%
  mutate(model="cultural resources") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod4 %>%
  mutate(model="parent resources") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("crude","fixed effects",
                                      "cultural resources",
                                      "parent resources")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))

ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```


## Summarizing the model results

Ok, let me first try to summarize these results, by group.

### Black/White results

For the first three models, the results are pretty consistent. Black/White biracials are much closer to the lower grade retention rates of whites, although they have rates that are clearly still higher than whites. Controlling for parental resources changes things considerably. First, the gap between Blacks and Whites shrinks considerably (visually it looks like its cut about in half). Second, Black/White biracials actually have lower rates than either group. They aren't that different than whites in effect size but the difference is statistically significant.

Why does the big change occur in the parental resources model? The descriptive stat table shows that the family resources of Black/White biracials are only slightly better than those of Black students and substantially worse than those of White students. So, Black/White biracials are at a disadvantage relative to whites, which is controlled for in the last model.

### Black/Latino results

In the crude model, its clear that there isn't much difference in the grade retention rates of Blacks and Latinos, with Blacks having a slightly higher rate than Latinos. The Black/Latino group has rates well below either of these groups. In fact, their grade retention rates in the crude model are closer to Whites. 

Interestingly, the fixed effects model reverses the ordering of Blacks and Latinos, but this is then reversed again in the cultural resources model. In addition the gap between Latinos and Blacks grows a little in the cultural resources model, which is expected. In all of these models, the Black/Latino group remains below either of those two groups, although the gap shrinks considerably across models. 

Things change quite a bit in the parent resources model. The gap between blacks and Latinos grows and the Black/Latino group now looks almost identical to the Latino group. So, some of their lower probability was due to better family resources, particularly relative to Latinos, as can be seen on the table of descriptive stats. Once that is controlled for, their outcomes are indistinguishable from Latino students.

### Black/Asian results

The crude and fixed effects models indicate that Black/Asian students have grade retention rates similar to the lower grade retention rates of Asian students. Controlling for cultural resources changes this somewhat with a point estimate that is higher than that of Asian students. This makes sense because Black/Asian students are much more likely than Asian students to be native born and speak English well with native-born parents who also speak English well. So this gave them and advantage which is removed in that model. The family resources model does not change the relative position of Black/Asian students, but does shrink the overall racial gap between Black and Asian students.

In the last two models, the confidence intervals overlap a bit, leading to greater uncertainty in the relatve placement of Black/Asian biracials. The point estimate suggests that their grade retention probability is between that of Asians and the half-way point, but the edge of the confidence intervals touch both those bands, so I cannot statistically distinguish their placement relative to those two possibilities. In any case, the results strongly rule out them being close to the outcomes of Black students, contra the hypodescent expectation.

### Black/Indigenous results

These results are quite noisy because of the smaller sample sizes involved. These are the two monoracial groups with the highest dropout rates, with or without controls. However, the difference between them is also quite large due to the very high grade retention probability for Indigenous students. This gap shrinks significantly in the model that adjusts for parental resources. 

Because of the noise its quite difficult to determine the relative placement of Black/Indigenous students at all, but we can rule out across all models that they have similar grade retentions rates to the higher grade retention of Indigenous students. The point estimate suggests a placement somewhere between the lower Black rate and the halfway point, but the wide CIs mean we cannot rule out either of those possibilities. 

The point estimate also gets much closer to the lower black rate once we control for family resources.

### White/Indigenous results

The results here consistently show that White/Indigenous students have grade retention rates about midway between the rates of whites and the halfway point. So they are clearly in the "lower half" between the groups and closer to White than Indigenous students. The overall gap between White and Indigenous students gets smaller with controls, but the relative placement of White/Indigenous students does not change.

###  White/Latino results

Importantly, the ordering of the monoracial groups shifts as controls are added to the model. The crude and fixed effets models show that White students are much less likely to be held back relative to Latino students. Controlling for cultural resources reduces this gap substantially and the inclusion of family resources flips its so that Latino students have slightly lower grade retention rates than Whites. So in the final model, there is not much room to find a midway point for White/Latino biracials. The final model shows outcomes that are similar to the lower rates of Latinos, although I need to check this more carefully because the CIs are not visible here relative to the dot (TODO). 

In the models prior to the inclusion of family resources, White/Latino biracials had grade retention rates similar to those of Whites, who had the lower rate. So despite the switch in ordering between Whites and Latinos, White/Latino biracials tend to look like the group with lower rates.

### White/Asian results

In all of the models prior to the inclusion of family resources, White/Asian students had grade retention rates slightly lower than the rates of Asians - the monoracial group with the lower rates. However, once controls are added for family resources, Asian/White students look just like Asian students (the lower group). This is because White/Asian students have the greatest family resources of any group in the dataset, even higher than those of White and Asian students. 

### Latino/Asian results

This is the group with the biggest outlier in terms of the effect. The initial results in the crude model suggested that Latino/Asian students had rates similar to the lower rates of Asian students. Controlling for cultural resources shifted this to rates that were exactly midway between the two monoracial groups. Controlling for family resources produced a point estimate that was *higher* than either monoracial group although not statistically distinguishable from the higher rates of Latinos. Notably, the gap between Asians and Latinos is also quite small in the final model. 

The change across models is a result of the high cultural and family resources of Latino/Asian students. However, their family resources do not seem particularly advantaged relative to Asian students, so something a bit complex is happening in the final model there. They look relatively worse compared to Latinos, but the relative difference doesn't change as much with respect to Asians. Essentially, once I control for family resources, they are "leapfrogged" by the Latino group.

### Indigenous/Latino results

Controlling for cultural resources makes a big difference here. Initially Indigenous/Latino students look the same as the lower Latino students. Controlling for cultural resources makes their outcomes indistinguishably from the midway point, althoug the point estimate is still in the lower half. Controlling for family resources has little effect.

Notably, because of sample size the error bars are substantially here.

### Indigenous/Asian results

This is a very small group ($n=521$) so the results are pretty noisy with wide CIs. However, the results are consistent across estimates. The grade retention rates of Indigenous/Asian students are similar to those of the lower Asian students. In the final model, the point estimate is almost identical to those for Asian students. 

Overall, I can put these results into a table where I specify the potential placement of each biracial group relative to their monoracial peers. There are seven possible outcomes:

* Lower than both groups
* Same as lower group
* Lower half
* Halfway between
* Upper half
* Same as higher
* Higher than both groups

For the two ends of the distribution and the lower half/upper half, I only consider these cases if it is statistically distinguishable from being in the other categories, respectively. For all other cases, I place an X in a cell if the confidence interval indicates this as a possibility. Asterisks indicate the placement of the point estimate for cases with uncertainty.

|                   | Lower than both | Same as lower | Lower half | Halfway | Upper half | Same as higher | Higher than both |
|-------------------|:---------------:|:-------------:|:----------:|:-------:|:----------:|:--------------:|:----------------:|
| Black/White       |        X        |               |            |         |            |                |                  |
| Black/Latino      |                 |       X       |            |         |            |                |                  |
| White/Asian       |                 |       X       |            |         |            |                |                  |
| White/Latino      |                 |       X       |            |         |            |                |                  |
| Indigenous/Asian  |                 |       X       |            |         |            |                |                  |
| Black Asian       |                 |       X       |     X*     |    X    |            |                |                  |
| Black/Indigenous  |                 |       X       |     X*     |    X    |            |                |                  |
| Indigenous/White  |                 |               |      X     |         |            |                |                  |
| Indigenous/Latino |                 |               |            |    X    |            |                |                  |
| Latino/Asian      |                 |               |            |         |            |        X       |                  |

The results I show here are based on model 4. They clearly show that most biracial groups are closer in outcomes to the monoracial group with the lower rates. In fact, half the groups have rates that are either indistinguishable from the lower group or lower than *both* groups. 

Being a part-black group in no way makes one more likely to suffer from hypodescent. In fact, the results for Black/White biracials where we would expect hypodescent to play the largest role are actually the farthest from hypodescent as possible. If any group seems to suffer from a pattern of hypodescent to some degree it is part-Indigenous groups and the Latino/Asian group. So something else is going on here.

In general, the results show that biracial groups are able to "slip through" the racialized structures that affect their more disadvantaged monoracial groups and this is not just a function of observable differences in class and nativity. 

## AMEs for single race groups

For the paper, I want a table showing the changes across single race groups. Lets go ahead and build that here based on the AMEs.

```{r monoracial-results, warning=FALSE, results='asis'}
results_monoracial <- map(list(model0, model1, model2, model3, model4),
                          function(x) {
                            marg(x, "race", type="effects", 
                                 vcov_mat=vcovCL(x, cluster=acs$cluster),
                                 at_var_interest=c("White","Black","Indigenous",
                                                   "Asian","Latino"))[[1]][-1,]
                          })

knitreg(map(results_monoracial, convert_marg),
        digits=3, caption="Average marginal differences in probability of being behind grade relative to whites",
        custom.gof.rows=list("State fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Year fixed effects" =   c("No","Yes","Yes","Yes","Yes"),
                             "Grade fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Metro fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Nativity and language" = c("No","No","Yes","Yes","Yes"),
                             "Parent's education" =    c("No","No","No","Yes","Yes"),
                             "Family resources" =      c("No","No","No","No","Yes")))


```

The results indicate that controlling for everything in model 5 reduces the racial disparities substantially. Comparing Model 5 to Model 2, the controls cut the effect in half for the Black and Indigenous groups. It has less effect and slightly increases the gap for Asians because Asians already had lower rates than Whites. The biggest change is for Latinos. In model 2, Latinos had the second highest probabilities and were 2% higher than whites. After controlling for everything, that actually reverse direction, such that Latinos have slightly lower expected probabilities than whites (.3% less). 

The gap is cut in half for Latinos by the nativity and language variables. These variables also increase the advantage of Asians as expected. they have no effect on the Black and Indigenous effects as expected.

So, I have to consider the shrinking (and in the case of Latinos, flipping direction) of these effects with controls when evaluating the placement of biracials.

# Sensitivity tests

## Models by grade

I want to separate the results by age more or less, but I cannot take age directly because then some kids cannot logically be behind grade at certain grade levels. For example, if I restrict to 11 or younger, then none of the 5th graders will be behind grade, by design. So, I will restrict by current grade level which indirectly gets at age. I am going to split it by elementary, middle school, and high school.

```{r models-by-grade, warning=FALSE, fig.height=12}
#run separate models by grade groups
model4_elem <- update(model4, data=subset(acs, current_grade<="5th"))
model4_middle <- update(model4, data=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th"))
model4_hs <- update(model4, data=subset(acs, current_grade>="9th"))


coef_table_elem <- calculate_marg_means(model4_elem, 
                                        cluster_var=subset(acs, current_grade<="5th")$cluster)
coef_table_middle <- calculate_marg_means(model4_middle,
                                          cluster_var=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th")$cluster)
coef_table_hs <- calculate_marg_means(model4_hs,
                                      cluster_var=subset(acs, current_grade>="9th")$cluster)

coef_table <- coef_table_elem %>%
  mutate(model="elementary")
coef_table <- coef_table_middle %>%
  mutate(model="middle school") %>%
  bind_rows(coef_table)
coef_table <- coef_table_hs %>%
  mutate(model="high school") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("elementary","middle school",
                                      "high school")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```

## Models with stricter parent linking

```{r models-parent-link, warning=FALSE, fig.height=12}
#run separate models by grade groups
model4_best_link <- update(model4, data=subset(acs, momrule==11 & poprule==11))

coef_table_best_link <- calculate_marg_means(model4_best_link, 
                                        cluster_var=subset(acs, momrule==11 &
                                                             poprule==11)$cluster)

coef_table <- coef_table_best_link %>%
  mutate(model="only direct links")
coef_table <- coef_table_mod4 %>%
  mutate(model="all links") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("all links","only direct links")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade",
       title="Probability of being behind grade for biracial respondents and monoracial comparison groups",
       caption="Non-overlap in confidence bands indicates statistically significant difference at the 5% level")
```


```{r time-end}
timestamp()
```