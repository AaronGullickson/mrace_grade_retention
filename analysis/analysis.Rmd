---
title: "Analysis for Biracial Grade Retention Project"
output: 
  rmdformats::robobook:
    highlight: tango
    toc_depth: 2
    fig_height: 6
    fig_width: 9
    code_folding: hide
    lightbox: TRUE
---


```{r time-start}
timestamp()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE)
library(here)
source(here("analysis","check_packages.R"))
source(here("analysis","useful_functions.R"))
load(here("analysis","output","acs.RData"))
```


# Grade retention summary

OK, first lets just confirm that the grade retention variable is working as expected on our sample. I start by looking at the number of kids by age and current grade:

```{r tab-grade-by-age}
acs %>% 
  tabyl(age, current_grade) %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Cross-tabulation of age and current grade of student",
      align=c("l",rep("r",13))) %>%
  kable_paper() %>%
  column_spec(2, background=c(rep("#D3D3D3",2), rep("white", 14))) %>%
  column_spec(3, background=c("white", 
                              rep("#D3D3D3",2), 
                              rep("white", 13))) %>%
  column_spec(4, background=c(rep("white", 2), 
                              rep("#D3D3D3",2), 
                              rep("white", 12))) %>%
  column_spec(5, background=c(rep("white", 3), 
                              rep("#D3D3D3",2), 
                              rep("white", 11))) %>%
  column_spec(6, background=c(rep("white", 4), 
                              rep("#D3D3D3",2), 
                              rep("white", 10))) %>%
  column_spec(7, background=c(rep("white", 5), 
                              rep("#D3D3D3",2), 
                              rep("white", 9))) %>%
  column_spec(8, background=c(rep("white", 6), 
                              rep("#D3D3D3",2), 
                              rep("white", 8))) %>%
  column_spec(9, background=c(rep("white", 7), 
                              rep("#D3D3D3",2), 
                              rep("white", 7))) %>%
  column_spec(10, background=c(rep("white", 8), 
                               rep("#D3D3D3",2), 
                               rep("white", 6))) %>%
  column_spec(11, background=c(rep("white", 9), 
                               rep("#D3D3D3",2), 
                               rep("white", 5))) %>%
  column_spec(12, background=c(rep("white", 10), 
                               rep("#D3D3D3",2), 
                               rep("white", 4))) %>%
  column_spec(13, background=c(rep("white", 11), 
                               rep("#D3D3D3",2), 
                               rep("white", 3))) %>%
  column_spec(14, background=c(rep("white", 12), 
                               rep("#D3D3D3",2), 
                               rep("white", 2)))
```

Ok, this looks more or less like what I would expect. We observe two modal ages for each grade. Some of the more extreme age values for older grades seem a little strange given that these are only supposed to be currently enrolled students. 20-year old sixth graders? I mean there are relatively few of these cases but still seems a bit odd. Its also interesting how this really starts expanding past 5th - did the Census Bureau "correct" values below 6th or something?

Now lets calculate the percentage of cases TRUE on the dependent variable across this same table, just to confirm its all working correctly.

```{r check-retention-code, fig.cap="The proportion of students measured at below grade level by age and current grade. This graph is used to ensure that the dependent variable is calculated correctly."}
acs %>%
  group_by(age, current_grade) %>%
  summarize(below=mean(below_exp_grade)) %>%
  ggplot(aes(x=current_grade, y=age, fill=below))+
  geom_tile(color="grey20")+
  geom_text(aes(label=below))+
  theme_bw()+
  scale_fill_viridis_c()+
  scale_y_continuous(breaks=5:20, minor_breaks = NULL)+
  labs(x="current grade", y="age", fill="proportion below grade level")
```

Ok, that looks good. 

What do the grade retention probabilities look like by grade:

```{r retention-by-grade, fig.cap="Percent of students clearly behind grade level by current grade. Blue lines fit a smoothed curve to the data."}
acs %>%
  group_by(current_grade) %>%
  summarize(below_grade=mean(below_exp_grade),
            n=n(),
            se=sqrt((below_grade*(1-below_grade))/n)) %>%
  ggplot(aes(x=current_grade, y=below_grade, group=1,
             ymin=below_grade-1.96*se, ymax=below_grade+1.96*se))+
  geom_smooth(se=FALSE)+
  geom_line(linetype=2, color="grey30")+
  geom_point()+
  geom_linerange()+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

I guess those numbers look pretty reasonable. Its hard to benchmark it off anything. Warren et. al. estimate annual retention rates by grade but that is different than what I am measuring here because this is cumulative (but can also reflect students being caught up). In general, these must be underestimates because they do not capture kids who were held back but are still within the modal age.

What about by year?

```{r retention-by-year, fig.cap="Trends over time in the percent of students clearly behind grade level. Blue lines fit a smoothed curve to the data."}
acs %>%
  group_by(year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade))+
  geom_line()+
  geom_point()+
  geom_smooth(se=FALSE)+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

Overall, there has been some decline over time in the prevalence of grade retention.

Lets look at this by grade and year

```{r retention-by-year-grade, fig.cap="Trends over time and grade in the percent of students clearly behind grade level. Lines are calculated by smoothing."}
acs %>%
  group_by(current_grade, year) %>%
  summarize(below_grade=mean(below_exp_grade)) %>%
  ggplot(aes(x=year, y=below_grade, group=current_grade, color=current_grade))+
  #geom_line()+
  geom_smooth(se=FALSE)+
  geom_point()+
  scale_x_continuous(breaks=c(2010,2014,2018))+
  scale_y_continuous(labels=scales::percent)+
  labs(x="current grade", y="percent clearly behind grade level for age")+
  theme_bw()
```

The evidence here suggests that the decline is driven by the higher grades where grade retention was higher overall.

# Descriptive statistics

Lets looks at sample characteristics by race.

```{r desc-stats}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(n=n(), 
            held_back=round(mean(below_exp_grade), 3)*100,
            mean_age=round(mean(age), 1),
            f_born=round(mean(foreign_born), 3)*100,
            spk_eng_well=round(mean(spk_eng=="Yes"), 3)*100,
            spk_eng_par=round(mean(spk_eng_father=="Yes" & 
                                     spk_eng_mother=="Yes"), 3)*100,
            par_fb=round(mean(foreign_born_father | 
                                       foreign_born_mother), 3)*100,
            fam_inc=round(mean(family_income), 0),
            own_home=round(mean(own_home), 3)*100,
            par_hs=round(mean(degree_father!="LHS" | 
                                degree_mother!="LHS"), 3)*100,
            par_ba=round(mean(degree_father=="BA" | 
                                degree_father=="G" | 
                                degree_mother=="BA" | 
                                degree_mother=="G"), 3)*100,
            par_mar=round(mean(parents_married), 3)*100) %>%
  arrange(desc(n))

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Descriptive statistics by race. Shading indicates biracial group. Groups ordered by sample size.",
      align = c("l",rep("r", ncol(tbl_summary)-1)),
      col.names=c("race","n","% below expected grade", "mean age",
                  "% foreign-born","% speak English well",
                  "% Both parents speak english well","% either parent foreign-born",
                  "mean family income","% own home","% either parent, HS diploma",
                  "% Either parent, BA degree","% parents married")) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```

# Model building

## Functional form of year-grade interactions

Before running the full models, I want to test out how I can parsimoniously address differences in the time trends by grade. 

```{r models-year-grade}
model_add_cat <- glm(below_exp_grade~as.factor(year)+current_grade+state, 
                     data=acs, family=binomial)
model_add_cont <- glm(below_exp_grade~I(year-2010)+current_grade+state, 
                     data=acs, family=binomial)
model_inter_cont <- glm(below_exp_grade~I(year-2010)*current_grade+state, 
                     data=acs, family=binomial)
model_inter_cat <- glm(below_exp_grade~as.factor(year)*current_grade+state, 
                     data=acs, family=binomial)
model_inter_state <- glm(below_exp_grade~I(year-2010)*current_grade+
                            I(year-2010)*state, 
                     data=acs, family=binomial)

sapply(list("categorical, additive"=model_add_cat,
            "categorical, interaction"=model_inter_cat, 
            "continuous, additive"=model_add_cont, 
            "continuous, interaction"=model_inter_cont,
            "add state*year continuous interaction"=model_inter_state),
       BIC) %>%
    enframe("model","BIC") %>%
  kbl() %>%
  kable_styling(full_width=FALSE)

# free some memory
rm(model_add_cat, model_add_cont, model_inter_cat, model_inter_cont,
   model_inter_state)
```

The preferred model by BIC is clearly the model that fits year as a continuous measure and interacts it with current grade, so that is what I will do. 

## Running the models

Here are the model structure that I will use:

0.  Raw race differences
1.  Add fixed effects for state, current grade, year, metro, and sex
2.  Add kids and parents foreign-born status.
3.  Add mother and father highest degree
4.  Add family income (square rooted), own your own home, and whether parents are married.

All models are estimated as logit models. Warning, the code chunks below take a bit of time to run!

```{r build-models, results='asis'}
model0 <- glm(below_exp_grade~race, data=acs, family=binomial)
model1 <- update(model0, 
                 .~.+I(year-2010)*current_grade+state+metro+sex)
model2 <- update(model1, 
                 .~.+foreign_born+foreign_born_mother+foreign_born_father+
                   spk_eng+spk_eng_mother+spk_eng_father)
model3 <- update(model2, .~.+degree_mother+degree_father)
model4 <- update(model3, .~.+sqrt(family_income/10000)+own_home+parents_married)

knitreg(list(model0, model1, model2, model3, model4))
```

## Differences for monoracial groups

The model results here are not very interesting directly because everything is relative to a single reference group. However, before proceeding with a technique for understanding the outcomes for biracial respondents, its worthwhile to look more closely at the differences between monoracial groups. The table below shows these differences using average marginal effects (AME) with whites as the reference.

```{r monoracial-results, warning=FALSE, results='asis'}
results_monoracial <- map(list(model0, model1, model2, model3, model4),
                          function(x) {
                            marg(x, "race", type="effects", 
                                 vcov_mat=vcovCL(x, cluster=acs$cluster),
                                 at_var_interest=c("White","Black","Indigenous",
                                                   "Asian","Latino"))[[1]][-1,]
                          })

knitreg(map(results_monoracial, convert_marg),
        digits=3, caption="Average marginal differences in probability of being behind grade relative to whites",
        custom.gof.rows=list("State fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Year fixed effects" =   c("No","Yes","Yes","Yes","Yes"),
                             "Grade fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Metro fixed effects" =  c("No","Yes","Yes","Yes","Yes"),
                             "Nativity and language" = c("No","No","Yes","Yes","Yes"),
                             "Parent's education" =    c("No","No","No","Yes","Yes"),
                             "Family resources" =      c("No","No","No","No","Yes")))

save(results_monoracial, file=here("analysis","output","monoracial_results.RData"))
```

The results indicate that controlling for everything in Model 5 reduces the racial disparities substantially. Comparing Model 5 to Model 2, the controls cut the effect in half for the Black and Indigenous groups. It has less effect and slightly increases the gap for Asians because Asians already had lower rates than Whites. The biggest change is for Latinos. In model 2, Latinos had the second highest probabilities and were 2% higher than whites. After controlling for everything, that actually reverse direction, such that Latinos have slightly lower expected probabilities than whites (.3% less). 

The gap is cut in half for Latinos by the nativity and language variables. These variables also increase the advantage of Asians as expected. they have no effect on the Black and Indigenous effects as expected.

So, I have to consider the shrinking (and in the case of Latinos, flipping direction) of these effects with controls when evaluating the placement of biracials.

## Average adjusted predictions for biracials

I want to compare each multiracial group to:

1.  Its two constituent monoracial groups (e.g. Compare Black/White to White and Black)
2.  The assumption that the biracial group will be halfway between the two constituent monoracial groups.

I can do this by calculating the *average adjusted prediction* of the dependent variable across all of the possible race groups. The average adjusted prediction (this is the stata-ese language - it is also called variously a predictive margin among other things). The adjusted predition in general is just the predicted value of the dependent variable for some set of values on the covariates. In this case, I want to predict on the level of the response to get predicted probabilities of being held back. The average adjusted prediction essentially gets the adjusted prediction for every observation in the data based on their covariates and then takes the average. Essentially, this is equivalent to treating every respondent as if they belonged to group A when calculating the average adjusted prediction for group A. The average adjusted prediction is directly related to the *average marginal effect* (AME) in that the AME for a group difference is simply the difference in the average adjusted prediction across groups.

Its easy to get a simple adjusted prediction at specific values using the `predict` command, but more complicated for the average adjusted prediction. In order to calculate these average adjusted predictions, I use the `marg` command in the `modmargs` library. This function has a nice `type="levels"` argument that directly gives you the average adjusted prediction. Standard errors for these average adjusted predictions are calculated by the [delta method](https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html). I also adjust all SEs for clustering of respondents within households.

To compare the results for each biracial group to the halfway assumption, I need to calculate the value midway between the two constituent groups and the standard error of that value. Calculating the midway value is just a straightforward mean calculation. To calculate the standard error, I take:

$$\frac{\sqrt{s_1^2+s_2^2}}{2}$$ where $s_1$ is the standard error for monoracial group 1 and $s_2$ is the standard error for monoracial group 2. This formula follows from the standard formulas for the variance of the sum of random variables.

In order to calculate all the values that I need, I have created a function that will put this into a nice table for later plotting.

```{r calc-cond-means, warning=FALSE}
coef_table_mod0 <- calculate_marg_means(model0)
```

Now I can use this nice table to plot out the results. I illustrate what this basic plot looks like below for the case of black/white individuals.

```{r example-plot, fig.cap="Probability of being behind grade for biracial black/white respondents in comparison to their monoracial comparison groups. 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level"}
g <- coef_table_mod0 %>%
  filter(mrace=="Black/White") %>%
  ggplot(aes(x=term, y=estimate, color=multiracial,
             ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod0, multiracial & mrace=="Black/White"))+
  geom_point()+
  coord_flip()+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="predicted probability of being behind expected grade")

g+annotate("text", 1, 0.035, hjust="left",
             label="Grey bands give 83.4%\nconfidence interval around\nmonoracial estimates")+
  annotate("text", 2, 0.045, hjust="left",
             label="Red band gives 83.4%\nconfidence interval around\nmidpoint estimate")+
  annotate("text", 2.5, 0.036, hjust="left",
             label="Actual biracial estimate\nshown with 83.4% confidence\ninterval")
```

This result is from the baseline model with no control variables, so this would be identical to the result you would get by just calculating raw proportions and their binomial standard errors (although the SEs are slightly different because this model accounts for clustering). The grey bands for the monoracial groups bookmark the range of results we might expect and the red band gives what would be the midpoint value between the groups, adjusting for statistical uncertainty. I can then see where the actual biracial estimate falls within this range. The results here indicate that biracial black/white students have probabilities of grade retention much closer to the lower values of white than black students. However, their probability is still a bit higher than that for whites.

Why I am using 83% (technically 83.4%) confidence intervals? This is a nice visual trick. People often incorrectly believe that overlapping 95% confidence intervals on two means indicates that the difference in the means is not statistically significant at $p<.05$. This is not always true and leads in practice to a much lower $\alpha$ for rejection. A much better approximation is given when one uses1.386 rather than 1.96 in estimating the confidence interval, which produces an 83.4% confidence interval. The intuition behind this technique is given nicely [here](https://chris-said.io/2014/12/01/independent-t-tests-and-the-83-confidence-interval-a-useful-trick-for-eyeballing-your-data/). Because I use this interval, we can know that if intervals (or bands) do not overlap, then the difference in means between the two groups is statistically significant at $p<.05$. In this case, the biracial estimate is statistically significantly different from both monoracial estimates as well as the "halfway" estimate. In short, biracial black/white students are held back at rates much closer but somewhat higher than whites, rather than blacks.

Its important to note that this technique is just an approximation because it depends on the assumption that the standard errors for the two means are the same, which is not going to be true here. However, it should give results that are quite close. Correcting for unequal SEs is far more complicated because the interval used will vary for any pairwise comparison which I am not doing here. 

The results here are the same as the raw differences, but I can also fit this graph to any of the models, using the average adjusted predictions. The plot below does this for model 4, by panelizing each multiracial group.

```{r cond-means-model4, warning=FALSE, fig.cap="Probability of being behind grade for biracial respondents in comparison to their monoracial comparison groups. 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level. Estimates are based on models that adjust for state, year, current grade, metropolitan status, gender, foreign born status, parent's foreign born status, English proficieny, parent's English proficiency, parent's education, family income, home ownership, and family structure."}
coef_table_mod4 <- calculate_marg_means(model4)

ggplot(coef_table_mod4, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table_mod4, multiracial))+
  geom_point()+
  coord_flip()+
  facet_wrap(~mrace, ncol=3, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade")
```

As the table here shows, after controlling for other stuff, most multiracial groups are quite similar to the monoracial constituent group with the lower grade retention rate. The only case where the biracial group is more like the higher monoracial group is for Latino/Asians. The results for indigenous groups are also quite noisy due to small size, but are generally consistent with the "below the halfway point."

To compare these results across models, I can try a very large figure that panelizes by model on the column and group on the row.

```{r cond-means-model-compare, fig.height=12, warning=FALSE, fig.cap="Probability of being behind grade for biracial respondents in comparison to their monoracial comparison groups. 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level. Each panel is based on a different model that accounts for certain variables. Subsequent panels cumulatively include all prior terms."}
#calculate remaining marginal means
coef_table_mod1 <- calculate_marg_means(model1)
coef_table_mod2 <- calculate_marg_means(model2)

coef_table <- coef_table_mod0 %>%
  mutate(model="crude")
coef_table <- coef_table_mod1 %>%
  mutate(model="fixed effects") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod2 %>%
  mutate(model="cultural resources") %>%
  bind_rows(coef_table)
coef_table <- coef_table_mod4 %>%
  mutate(model="parent resources") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("crude","fixed effects",
                                      "cultural resources",
                                      "parent resources")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))

ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade")

save(coef_table, file=here("analysis","output","coef_table.RData"))
```


## Summarizing the model results

Ok, let me first try to summarize these results, by group.

### Black/White results

For the first three models, the results are pretty consistent. Black/White biracials are much closer to the lower grade retention rates of whites, although they have rates that are clearly still higher than whites. Controlling for parental resources changes things considerably. First, the gap between Blacks and Whites shrinks considerably (visually it looks like its cut about in half). Second, Black/White biracials actually have lower rates than either group. They aren't that different than whites in effect size but the difference is statistically significant.

Why does the big change occur in the parental resources model? The descriptive stat table shows that the family resources of Black/White biracials are only slightly better than those of Black students and substantially worse than those of White students. So, Black/White biracials are at a disadvantage relative to whites, which is controlled for in the last model.

### Black/Latino results

In the crude model, its clear that there isn't much difference in the grade retention rates of Blacks and Latinos, with Blacks having a slightly higher rate than Latinos. The Black/Latino group has rates well below either of these groups. In fact, their grade retention rates in the crude model are closer to Whites. 

Interestingly, the fixed effects model reverses the ordering of Blacks and Latinos, but this is then reversed again in the cultural resources model. In addition the gap between Latinos and Blacks grows a little in the cultural resources model, which is expected. In all of these models, the Black/Latino group remains below either of those two groups, although the gap shrinks considerably across models. 

Things change quite a bit in the parent resources model. The gap between blacks and Latinos grows and the Black/Latino group now looks almost identical to the Latino group. So, some of their lower probability was due to better family resources, particularly relative to Latinos, as can be seen on the table of descriptive stats. Once that is controlled for, their outcomes are indistinguishable from Latino students.

### Black/Asian results

The crude and fixed effects models indicate that Black/Asian students have grade retention rates similar to the lower grade retention rates of Asian students. Controlling for cultural resources changes this somewhat with a point estimate that is higher than that of Asian students. This makes sense because Black/Asian students are much more likely than Asian students to be native born and speak English well with native-born parents who also speak English well. So this gave them and advantage which is removed in that model. The family resources model does not change the relative position of Black/Asian students, but does shrink the overall racial gap between Black and Asian students.

In the last two models, the confidence intervals overlap a bit, leading to greater uncertainty in the relatve placement of Black/Asian biracials. The point estimate suggests that their grade retention probability is between that of Asians and the half-way point, but the edge of the confidence intervals touch both those bands, so I cannot statistically distinguish their placement relative to those two possibilities. In any case, the results strongly rule out them being close to the outcomes of Black students, contra the hypodescent expectation.

### Black/Indigenous results

These results are quite noisy because of the smaller sample sizes involved. These are the two monoracial groups with the highest dropout rates, with or without controls. However, the difference between them is also quite large due to the very high grade retention probability for Indigenous students. This gap shrinks significantly in the model that adjusts for parental resources. 

Because of the noise its quite difficult to determine the relative placement of Black/Indigenous students at all, but we can rule out across all models that they have similar grade retentions rates to the higher grade retention of Indigenous students. The point estimate suggests a placement somewhere between the lower Black rate and the halfway point, but the wide CIs mean we cannot rule out either of those possibilities. 

The point estimate also gets much closer to the lower black rate once we control for family resources.

### White/Indigenous results

The results here consistently show that White/Indigenous students have grade retention rates about midway between the rates of whites and the halfway point. So they are clearly in the "lower half" between the groups and closer to White than Indigenous students. The overall gap between White and Indigenous students gets smaller with controls, but the relative placement of White/Indigenous students does not change.

###  White/Latino results

Importantly, the ordering of the monoracial groups shifts as controls are added to the model. The crude and fixed effets models show that White students are much less likely to be held back relative to Latino students. Controlling for cultural resources reduces this gap substantially and the inclusion of family resources flips its so that Latino students have slightly lower grade retention rates than Whites. So in the final model, there is not much room to find a midway point for White/Latino biracials. The final model shows outcomes that are similar to the lower rates of Latinos, although I need to check this more carefully because the CIs are not visible here relative to the dot (TODO). 

In the models prior to the inclusion of family resources, White/Latino biracials had grade retention rates similar to those of Whites, who had the lower rate. So despite the switch in ordering between Whites and Latinos, White/Latino biracials tend to look like the group with lower rates.

### White/Asian results

In all of the models prior to the inclusion of family resources, White/Asian students had grade retention rates slightly lower than the rates of Asians - the monoracial group with the lower rates. However, once controls are added for family resources, Asian/White students look just like Asian students (the lower group). This is because White/Asian students have the greatest family resources of any group in the dataset, even higher than those of White and Asian students. 

### Latino/Asian results

This is the group with the biggest outlier in terms of the effect. The initial results in the crude model suggested that Latino/Asian students had rates similar to the lower rates of Asian students. Controlling for cultural resources shifted this to rates that were exactly midway between the two monoracial groups. Controlling for family resources produced a point estimate that was *higher* than either monoracial group although not statistically distinguishable from the higher rates of Latinos. Notably, the gap between Asians and Latinos is also quite small in the final model. 

The change across models is a result of the high cultural and family resources of Latino/Asian students. However, their family resources do not seem particularly advantaged relative to Asian students, so something a bit complex is happening in the final model there. They look relatively worse compared to Latinos, but the relative difference doesn't change as much with respect to Asians. Essentially, once I control for family resources, they are "leapfrogged" by the Latino group.

### Indigenous/Latino results

Controlling for cultural resources makes a big difference here. Initially Indigenous/Latino students look the same as the lower Latino students. Controlling for cultural resources makes their outcomes indistinguishably from the midway point, althoug the point estimate is still in the lower half. Controlling for family resources has little effect.

Notably, because of sample size the error bars are substantially here.

### Indigenous/Asian results

This is a very small group ($n=521$) so the results are pretty noisy with wide CIs. However, the results are consistent across estimates. The grade retention rates of Indigenous/Asian students are similar to those of the lower Asian students. In the final model, the point estimate is almost identical to those for Asian students. 

Overall, I can put these results into a table where I specify the potential placement of each biracial group relative to their monoracial peers. There are seven possible outcomes:

* Lower than both groups
* Same as lower group
* Lower half
* Halfway between
* Upper half
* Same as higher
* Higher than both groups

For the two ends of the distribution and the lower half/upper half, I only consider these cases if it is statistically distinguishable from being in the other categories, respectively. For all other cases, I place an X in a cell if the confidence interval indicates this as a possibility. Asterisks indicate the placement of the point estimate for cases with uncertainty.

|                   | Lower than both | Same as lower | Lower half | Halfway | Upper half | Same as higher | Higher than both |
|-------------------|:---------------:|:-------------:|:----------:|:-------:|:----------:|:--------------:|:----------------:|
| Black/White       |        X        |               |            |         |            |                |                  |
| Black/Latino      |                 |       X       |            |         |            |                |                  |
| White/Asian       |                 |       X       |            |         |            |                |                  |
| White/Latino      |                 |       X       |            |         |            |                |                  |
| Indigenous/Asian  |                 |       X       |            |         |            |                |                  |
| Black Asian       |                 |       X       |     X*     |    X    |            |                |                  |
| Black/Indigenous  |                 |       X       |     X*     |    X    |            |                |                  |
| Indigenous/White  |                 |               |      X     |         |            |                |                  |
| Indigenous/Latino |                 |               |            |    X    |            |                |                  |
| Latino/Asian      |                 |               |            |         |            |        X       |                  |

The results I show here are based on model 4. They clearly show that most biracial groups are closer in outcomes to the monoracial group with the lower rates. In fact, half the groups have rates that are either indistinguishable from the lower group or lower than *both* groups. 

Being a part-black group in no way makes one more likely to suffer from hypodescent. In fact, the results for Black/White biracials where we would expect hypodescent to play the largest role are actually the farthest from hypodescent as possible. If any group seems to suffer from a pattern of hypodescent to some degree it is part-Indigenous groups and the Latino/Asian group. So something else is going on here.

In general, the results show that biracial groups are able to "slip through" the racialized structures that affect their more disadvantaged monoracial groups and this is not just a function of observable differences in class and nativity. 

## Sensitivity tests

### Models by grade

I want to separate the results by age more or less, but I cannot take age directly because then some kids cannot logically be behind grade at certain grade levels. For example, if I restrict to 11 or younger, then none of the 5th graders will be behind grade, by design. So, I will restrict by current grade level which indirectly gets at age. I am going to split it by elementary, middle school, and high school.

```{r models-by-grade, warning=FALSE, fig.height=12, fig.cap="Probability of being behind grade for biracial respondents in comparison to their monoracial comparison groups. 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level. Panels compare results when data are restricted to certain grade ranges."}
#run separate models by grade groups
model4_elem <- update(model4, data=subset(acs, current_grade<="5th"))
model4_middle <- update(model4, data=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th"))
model4_hs <- update(model4, data=subset(acs, current_grade>="9th"))


coef_table_elem <- calculate_marg_means(model4_elem, 
                                        cluster_var=subset(acs, current_grade<="5th")$cluster)
coef_table_middle <- calculate_marg_means(model4_middle,
                                          cluster_var=subset(acs, current_grade>"5th" & 
                                        current_grade<"9th")$cluster)
coef_table_hs <- calculate_marg_means(model4_hs,
                                      cluster_var=subset(acs, current_grade>="9th")$cluster)

coef_table <- coef_table_elem %>%
  mutate(model="elementary")
coef_table <- coef_table_middle %>%
  mutate(model="middle school") %>%
  bind_rows(coef_table)
coef_table <- coef_table_hs %>%
  mutate(model="high school") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("elementary","middle school",
                                      "high school")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade")
```

The results get quite a bit noisier here because we are cutting the sample size substantially in each panel. The general pattern is that the results tend to look pretty similar across grade levels. What variations we do see could easily be the result of statistical noise as they tend to move around the most in cases with high error bands. The two notable cases where something might be going on:

* For White/Black students, grade retention is clearly in the lower-half between Whites and the midway point rather than below whites for high school students. Notably, this is also where the white/black grows the largest. So the advantage that these students have relative to everyone else only holds for elementary and middle school. Nonetheless, their outcomes are still much closer to White students than Black students.
* For White/Indigenous students, the placement varies across panels. In elementary school, these students are indistinguishable from White students. They are perfectly in the middle in middle school, and then in the lower half in high school. So it seems that their lowest outcomes happen earlier and on average you end up with a "lower half" across all grades. 

In no case do the results here suggest a biasing effect of non-biological kids. We would expect that to be greater in higher grades, but the results are generally consistent across grades. In cases where they are not consistent, you would expect the results to move toward the larger population group with age, but I do not see that.

### Models with stricter parent linking

```{r models-parent-link, warning=FALSE, fig.height=12, fig.cap="Probability of being behind grade for biracial respondents in comparison to their monoracial comparison groups. 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level. Panels compare results depending on whether results are restricted only to children linked to a head of household or not."}
#run separate models by grade groups
model4_best_link <- update(model4, data=subset(acs, momrule==11 & poprule==11))

coef_table_best_link <- calculate_marg_means(model4_best_link, 
                                        cluster_var=subset(acs, momrule==11 &
                                                             poprule==11)$cluster)

coef_table <- coef_table_best_link %>%
  mutate(model="only direct links")
coef_table <- coef_table_mod4 %>%
  mutate(model="all links") %>%
  bind_rows(coef_table) %>%
  mutate(model=factor(model, levels=c("all links","only direct links")),
         mrace=factor(mrace, levels=c("Black/White",
                                      "Black/Latino",
                                      "Black/Asian",
                                      "Black/Indigenous",
                                      "White/Indigenous",
                                      "White/Latino",
                                      "White/Asian",
                                      "Latino/Asian",
                                      "Indigenous/Latino",
                                      "Indigenous/Asian")))
  
ggplot(coef_table, aes(x=term, y=estimate, color=multiracial,
                       ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
  geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
            color=NA, alpha=0.2)+
  geom_linerange(data=subset(coef_table, multiracial))+
  geom_point()+
  coord_flip()+
  facet_grid(mrace~model, scales="free_y")+
  theme_bw()+
  theme(legend.position = "none", panel.grid = element_blank())+
  scale_color_manual(values=c("grey40","red"))+
  scale_fill_manual(values=c("grey40","red"))+
  scale_linetype_manual(values=c(3,1))+
  scale_y_continuous(labels = scales::percent)+
  labs(x=NULL,
       y="average adjusted predicted probability of being behind expected grade")
```

The results here are extraordinarily stable across both specifications. 

# Differences in Cultural and Family Resources

First, lets compare means of SES and cultural resources across all racial groups.

```{r desc-stats-ses}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(fam_inc=round(mean(family_income), 0),
            own_home=round(mean(own_home), 3)*100,
            par_mar=round(mean(parents_married), 3)*100,
            f_lhs=round(mean(degree_father=="LHS"), 3)*100,
            f_hs=round(mean(degree_father=="HS"), 3)*100,
            f_aa=round(mean(degree_father=="AA"), 3)*100,
            f_ba=round(mean(degree_father=="BA" | degree_father=="G"), 3)*100,
            m_lhs=round(mean(degree_mother=="LHS"), 3)*100,
            m_hs=round(mean(degree_mother=="HS"), 3)*100,
            m_aa=round(mean(degree_mother=="AA"), 3)*100,
            m_ba=round(mean(degree_mother=="BA" | degree_mother=="G"), 3)*100)

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="SES resources by race. Shading indicates biracial group.",
      align = c("l",rep("r", ncol(tbl_summary)-1)),
      col.names=c("race","mean family income","% own home",
                  "% parents married",
                  "% father, no HS diploma","% father, HS diploma",
                  "% father, AA degree",  "% father, BA+ degree",
                  "% mother, no HS diploma","% mother, HS diploma", 
                  "%  mother, AA degree", "% mother, BA+ degree")) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```

There is a lot going on here, but I can summarize a few things:

- Most multiracial groups are more like the more privileged constituent group than the less privileged constituent group across all of these characteristics. For example, White/Latino respondents have family incomes of \$130,981 compared to \$138,489 for Whites and \$64,920 for Latinos. Similarly, 9.6% and 11.6% of Latino fathers and mothers, respectively, have a BA degree, compared to 43.8% and 47.6% for Whites, and 38.6% and 41.5% for White/Latinos. Also White/Latino parents own their home in 86.7% of cases which is similar to the white value of 85.5% and much higher than the 54.3% for Latinos.
- Black/Whites in contrast, are much more like Blacks in terms of their resources and both groups have fewer resources than Whites.
- White/Asians are the most privileged group of all, even more so than their two constituent groups. Their family income of \$195,028 is off the charts! but they also have parents with very high educational attainment.
- Most part-Indigenous groups also buck the modal trend and have outcomes that are about halfway between their two constituent groups. The one part-Indigenous group that does not follow that pattern is the Indigenous/Latino group, which tend to have resources slightly better than both of the monoracial groups (although still very low compared to everyone else).

Now lets look at the cultural characteristics. One thing to keep in mind here is that having foreign-born parents actually *lowers* your risk of grade retention, whereas being foreign-born yourself increases it.

```{r desc-stats-cult}
tbl_summary <- acs %>%
  group_by(race) %>%
  summarize(f_born=round(mean(foreign_born), 3)*100,
            father_fb=round(mean(foreign_born_father), 3)*100,
            mother_fb=round(mean(foreign_born_mother), 3)*100,
            spk_eng_no=round(mean(spk_eng=="No"), 3)*100,
            spk_eng_some=round(mean(spk_eng=="Somewhat"), 3)*100,
            spk_eng_yes=round(mean(spk_eng=="Yes"), 3)*100,
            f_spk_eng_no=round(mean(spk_eng_father=="No"), 3)*100,
            f_spk_eng_some=round(mean(spk_eng_father=="Somewhat"), 3)*100,
            f_spk_eng_yes=round(mean(spk_eng_father=="Yes"), 3)*100,
            m_spk_eng_no=round(mean(spk_eng_mother=="No"), 3)*100,
            m_spk_eng_some=round(mean(spk_eng_mother=="Somewhat"), 3)*100,
            m_spk_eng_yes=round(mean(spk_eng_mother=="Yes"), 3)*100)

index_biracial <- which(str_detect(tbl_summary$race, "/"))

tbl_summary %>%
  mutate_if(is.numeric, format, big.mark=",") %>%
  kbl(caption="Cultural resources by race. Shading indicates biracial group.",
      align = c("l",rep("r", ncol(tbl_summary)-1)),
      col.names=c("race",
                  "% foreign-born","% father foreign-born",
                  "% mother foreign-born",
                  "% speak no English", "% speak some English", 
                  "% speak English",
                  "% father speak no English", "% father speak some English", 
                  "% father speak English",
                  "% mother speak no English", "% mother speak some English",
                  "% mother speak English")) %>%
  kable_paper() %>%
  row_spec(index_biracial, background = "#D3D3D3")
```
* In general, the most notable thing here is that in terms of English proficiency (both respondent and parents), all of the biracial groups involving Latino and Asian have almost universal proficiency (>99%) and more like the non-Latino and non-Asian groups. This is most notable for Latinos where only about two-thirds of fathers and mothers of monoracial Latinos have full English proficiency but all of the part Latino multiracial groups have parents that are 99% or more fluent. So, there is heavy selection on English proficiency into interracial unions, which is not surpising.
* We also see that part-Latino and part-Asian respondents are much more likely to be native born and to have native-born parents than Latino and Asian respondents. The effects are large although not quite as huge as for language. However, because foreign-born parents actually *reduce* the effect of grade retention, the ultimate effect of this selection is more complex.

One way to boil down the complexity of these tables into something easier to understand would be to calculate average predicted probability for each racial group, while holding constant all non-resource variables *including race*. These probabilities provide a counterfactual estimate of what the average probability would be for each group if they only differed on the resource variables, allowing me to isolate how different distributions of resources across racial groups affect the risk of grade retention.

To do this, the following variables need to be set at some constant value to be held constant:

- current grade
- state
- year
- metro status
- gender
- race

One could just plug in some static values (e.g. make everyone White, from Minnesota, in 6th grade, etc.), but this feels pretty ad-hoc. I think the best approach is to set all of these values at their mean. Since most of these variables are categorical variables, this means treating them as 0/1 dummies and then calculating the proportion as the mean. Unfortunately, this approach won't work with the models built above because they made use of factor variables. So, to run these models, I first need to create actual 0/1 dummies for the categorical variables listed above (current grade, state, metro status, gender, race). That is what the code below does.

```{r create-dummied-data}
acs_dummied <- acs %>%
  # first we need to unorder current grade for dummy_cols to work
  mutate(current_grade=factor(current_grade, levels=levels(current_grade), 
                              ordered = FALSE)) %>%
  
  dummy_cols(remove_first_dummy = TRUE) %>%
  select(cluster, strata, perwt, below_exp_grade, year, family_income, 
         parents_married, own_home, degree_mother, degree_father,
         foreign_born, foreign_born_mother, foreign_born_father, 
         spk_eng, spk_eng_father, spk_eng_mother,
         starts_with(c("state_","current_grade_","race","sex_","metro_"))) %>%
  mutate(year=year-2010) %>%
  clean_names()
```

Now that I have new "dummied up" dataset, I can rereun the full model using the dummy variables which means a very, very long formula.

```{r model-dummied}
model_full <- glm(below_exp_grade~
                    year*(current_grade_1st+current_grade_2nd+current_grade_3rd+
                            current_grade_4th+current_grade_5th+
                            current_grade_6th+current_grade_7th+
                            current_grade_8th+current_grade_9th+
                            current_grade_10th+current_grade_11th+
                            current_grade_12th)+
                    race_black+race_indigenous+race_asian+race_latino+
                    race_black_white+race_black_indigenous+race_black_latino+
                    race_black_asian+race_white_indigenous+race_white_latino+
                    race_white_asian+race_indigenous_latino+
                    race_indigenous_asian+race_latino_asian+
                    sex_female+
                    metro_non_metro+metro_central_city+metro_metro_non_central+
                    metro_metro_indeterminable+
                    state_alaska+state_arizona+state_arkansas+state_california+
                    state_colorado+state_connecticut+state_dc+state_delaware+
                    state_florida+state_georgia+state_hawaii+state_idaho+
                    state_illinois+state_indiana+state_iowa+state_kansas+
                    state_kentucky+state_louisiana+state_maine+state_maryland+
                    state_massachusetts+state_michigan+state_minnesota+
                    state_mississippi+state_missouri+state_montana+
                    state_nebraska+state_nevada+state_new_hampshire+
                    state_new_jersey+state_new_mexico+state_new_york+
                    state_north_carolina+state_north_dakota+state_ohio+
                    state_oklahoma+state_oregon+state_pennsylvania+
                    state_rhode_island+state_south_carolina+state_south_dakota+
                    state_tennessee+state_texas+state_utah+state_vermont+
                    state_virginia+state_washington+state_west_virginia+
                    state_wisconsin+state_wyoming+
                    +sqrt(family_income/10000)+parents_married+own_home+
                    degree_mother+degree_father+
                    spk_eng+spk_eng_mother+spk_eng_father+
                    foreign_born_mother+foreign_born_father+foreign_born, 
                  data=acs_dummied, family=binomial)
```

I now have the model in the correct form. The next step is to create the counterfactual dataset by setting all of the non-resource variables to their mean. Thus, in this dataset, the only differences across racial groups are coming from their resource differences.

```{r create-cf-df}
# Create the counterfactual dataset where non-resource variables are held
# at their mean. What needs to be set at tis mean?
# - current_grade
# - sex
# - race
# - state
# - metro
# - year
means <- acs_dummied %>%
  select(year, starts_with(c("state_","current_grade_","race_","sex_",
                             "metro_"))) %>%
  lapply(function(x) {rep(mean(x), length(x))}) %>%
  bind_rows()

cf_df <- acs_dummied %>%
  select(cluster, strata, perwt, below_exp_grade, race,family_income, 
         parents_married, own_home, degree_mother, degree_father, foreign_born, 
         foreign_born_mother, foreign_born_father, spk_eng, spk_eng_father, 
         spk_eng_mother) %>%
  bind_cols(means)
```

```{r test-marg, eval=FALSE}
# This code chunk just tests to make sure I get the same value by hand as I get 
# when I do it through the marg command.
temp <- subset(cf_df, race=="Black/White")
lor <- predict(model_full, newdata=temp)
mean(exp(lor)/(1+exp(lor)))
marg(model_full, "year", data=temp)
# It works!
```

I can then feed subsets (by race) of this counterfactual dataset into the `marg` command to get the predicted probability of grade retention for each racial group as I do below.

```{r create-cf-marg}
coefs <- lapply(unique(acs$race), function(x) {
  temp <- subset(cf_df, race==x)
  means_margin <- marg(model_full, "year", data=temp)[[1]]
  return(tibble(term=x, estimate=means_margin$Margin, 
                se=means_margin$Standard.Error))
}) %>%
  bind_rows()

coef_table_cf <- create_coef_table(coefs)
```

And now I can plot up the results.

```{r counterfactual-ses, warning=FALSE, fig.cap="Counterfactual probability of being behind grade for biracial respondents in comparison to their monoracial comparison groups if the only differences between groups were resources (household income, parental education, home ownership, parent and child foreign-born status, parent and child English proficiency, and whether parents are married). 83.4% confidence bands shown around each estimate. Non-overlap in confidence bands roughly indicates statistically significant difference at the 5% level."}
  ggplot(coef_table_cf, aes(x=term, y=estimate, color=multiracial,
                         ymin=estimate-1.386*se, ymax=estimate+1.386*se))+
    geom_rect(aes(xmax=Inf, xmin=-Inf, ymin=estimate_mid-1.386*se_mid,
                  ymax=estimate_mid+1.386*se_mid, fill=multiracial), 
              color=NA, alpha=0.2)+
    geom_linerange(data=subset(coef_table_cf, multiracial))+
    geom_point()+
    coord_flip()+
    facet_wrap(~mrace, scales="free_y")+
    theme_bw()+
    theme(legend.position = "none", panel.grid = element_blank())+
    scale_color_manual(values=c("grey40","red"))+
    scale_fill_manual(values=c("grey40","red"))+
    scale_linetype_manual(values=c(3,1))+
    scale_y_continuous(labels = scales::percent)+
    labs(x=NULL,
         y="average adjusted predicted probability of being behind expected grade")
  
```

I summarize the results here:

|                   | Lower than both | Same as lower | Between | Same as higher | Higher than both |
|-------------------|:---------------:|:-------------:|:-------:|:--------------:|:----------------:|
| White/Asian       |       X         |               |         |                |                  |
| Black/Asian       |                 |  X  (Asian)   |         |                |                  |
| Black/Latino      |                 |  X  (Black)   |         |                |                  |
| White/Latino      |                 |  X  (White)   |         |                |                  |
| Indigenous/Latino |                 |X  (Indigenous)|         |                |                  |
| Latino/Asian      |                 |  X (Asian)    |         |                |                  |
| White/Indigenous  |                 |               |    X    |                |                  |
| Indigenous/Asian  |                 |               |    X    |                |                  |
| Black/Indigenous  |                 |               |    X    |                |                  |
| Black/White       |                 |               |         |   X (Black)    |                  |


In half the cases, the biracial group would have outcomes similar to the group with better resources suggesting that the parents in these matches are being positively selected. The White/Asian case is even more dramatic with a resource advantage over both single race groups. You can see this particularly for the White/Asian case in terms of family income where they have the highest of *any* group by a considerable amount. White/Asians are on average a very privileged group.

Three groups that have the "expected" in-between status based on resources all share one thing in common - they are part-Indigenous. That is not true of the Indigenous/Latino case, but is of all others. It suggests less selectivity in crossing this boundary.

Finally, the Black/White case stands out in that Black/White kids have the same risk of being held back based on their resources as do Black kids. Thus, they are not getting a resource boost nor does it seem like they are particularly positively selected.

So the effects of controlling for these resources will be complex and different across groups. In general for those that are the same as lower or lower than both, we see that it pulls their relative probability up somewhat. For the Black/White case, it pulls their probability down on the other hand. For the "between" groups its more complex and doesn't seem to do much in total.

Lets see if I can put all of this into a simpler table that summarize the key issues.

```{r time-end}
timestamp()
```